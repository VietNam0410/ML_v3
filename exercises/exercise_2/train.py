import streamlit as st
import numpy as np
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.cluster import KMeans, DBSCAN
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, silhouette_score
from sklearn.preprocessing import StandardScaler
import mlflow
import os

# Thi·∫øt l·∫≠p MLflow Tracking URI c·ª•c b·ªô
if not os.path.exists('mlruns'):
    os.makedirs('mlruns')
mlflow.set_tracking_uri(f"file://{os.path.abspath('mlruns')}")

def train_mnist():
    st.header("Hu·∫•n luy·ªán M√¥ h√¨nh Nh·∫≠n di·ªán Ch·ªØ s·ªë MNIST üßÆ")

    # Cho ng∆∞·ªùi d√πng ƒë·∫∑t t√™n Experiment
    experiment_name = st.text_input("Nh·∫≠p T√™n Experiment cho Hu·∫•n luy·ªán", value="MNIST_Training")
    if experiment_name:
        mlflow.set_experiment(experiment_name)
    
    # Ki·ªÉm tra d·ªØ li·ªáu ƒë√£ ti·ªÅn x·ª≠ l√Ω trong MLflow (thay v√¨ session_state)
    # S·ª≠a ƒë·ªïi b·ªüi Grok 3: Lo·∫°i b·ªè session_state, ch·ªâ d√πng MLflow
    preprocess_runs = mlflow.search_runs(experiment_names=["MNIST_Preprocessing"])
    if preprocess_runs.empty:
        st.error("D·ªØ li·ªáu MNIST ƒë√£ x·ª≠ l√Ω kh√¥ng t√¨m th·∫•y trong MLflow. Vui l√≤ng ho√†n t·∫•t ti·ªÅn x·ª≠ l√Ω trong 'Ti·ªÅn x·ª≠ l√Ω D·ªØ li·ªáu MNIST' tr∆∞·ªõc.")
        return

    latest_preprocess_run_id = preprocess_runs['run_id'].iloc[0]
    split_runs = mlflow.search_runs(experiment_names=["MNIST_Preprocessing"], filter_string=f"tags.mlflow.runName LIKE '%Split%'")
    if split_runs.empty:
        st.error("D·ªØ li·ªáu chia t√°ch kh√¥ng t√¨m th·∫•y trong MLflow. Vui l√≤ng chia t√°ch d·ªØ li·ªáu trong 'Ti·ªÅn x·ª≠ l√Ω D·ªØ li·ªáu MNIST' tr∆∞·ªõc.")
        return

    latest_split_run_id = split_runs['run_id'].iloc[0]

    # T·∫£i d·ªØ li·ªáu t·ª´ MLflow
    X_train_path = mlflow.artifacts.download_artifacts(run_id=latest_split_run_id, path="X_train.npy")
    y_train_path = mlflow.artifacts.download_artifacts(run_id=latest_split_run_id, path="y_train.npy")
    X_valid_path = mlflow.artifacts.download_artifacts(run_id=latest_split_run_id, path="X_valid.npy")
    y_valid_path = mlflow.artifacts.download_artifacts(run_id=latest_split_run_id, path="y_valid.npy")
    X_test_path = mlflow.artifacts.download_artifacts(run_id=latest_split_run_id, path="X_test.npy")

    X_train = np.load(X_train_path).reshape(-1, 28 * 28)
    y_train = np.load(y_train_path)
    X_valid = np.load(X_valid_path).reshape(-1, 28 * 28)
    y_valid = np.load(y_valid_path)
    X_test = np.load(X_test_path).reshape(-1, 28 * 28)

    st.subheader("D·ªØ li·ªáu MNIST ƒë√£ x·ª≠ l√Ω t·ª´ MLflow üìù")
    st.write(f"S·ªë l∆∞·ª£ng m·∫´u hu·∫•n luy·ªán: {len(X_train)}")
    st.write(f"S·ªë l∆∞·ª£ng m·∫´u validation: {len(X_valid)}")
    st.write(f"S·ªë l∆∞·ª£ng m·∫´u ki·ªÉm tra: {len(X_test)}")

    # Chu·∫©n h√≥a d·ªØ li·ªáu cho c√°c m√¥ h√¨nh
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_valid_scaled = scaler.transform(X_valid)
    X_test_scaled = scaler.transform(X_test)

    # X√¢y d·ª±ng v√† hu·∫•n luy·ªán m√¥ h√¨nh
    st.subheader("X√¢y d·ª±ng v√† Hu·∫•n luy·ªán M√¥ h√¨nh üéØ")
    model_choice = st.selectbox(
        "Ch·ªçn lo·∫°i m√¥ h√¨nh",
        ["SVM (Support Vector Machine)", "Decision Tree", "K-means (Clustering)", "DBSCAN (Clustering)"]
    )

    # Tham s·ªë hu·∫•n luy·ªán cho t·ª´ng m√¥ h√¨nh
    if model_choice == "SVM (Support Vector Machine)":
        kernel = st.selectbox("Ch·ªçn kernel SVM", ["linear", "rbf", "poly"], index=1)
        C = st.slider("C (Regularization parameter)", 0.1, 10.0, 1.0, step=0.1)
        model_params = {"kernel": kernel, "C": C}
    elif model_choice == "Decision Tree":
        max_depth = st.slider("ƒê·ªô s√¢u t·ªëi ƒëa", 1, 20, 10, step=1)
        min_samples_split = st.slider("S·ªë m·∫´u t·ªëi thi·ªÉu ƒë·ªÉ chia", 2, 20, 2, step=1)
        model_params = {"max_depth": max_depth, "min_samples_split": min_samples_split}
    elif model_choice == "K-means (Clustering)":
        n_clusters = st.slider("S·ªë c·ª•m", 2, 20, 10, step=1)
        model_params = {"n_clusters": n_clusters}
    else:  # DBSCAN
        eps = st.slider("Epsilon (kho·∫£ng c√°ch t·ªëi ƒëa)", 0.1, 1.0, 0.5, step=0.1)
        min_samples = st.slider("S·ªë m·∫´u t·ªëi thi·ªÉu", 1, 10, 5, step=1)
        model_params = {"eps": eps, "min_samples": min_samples}

    if st.button("Hu·∫•n luy·ªán m√¥ h√¨nh"):
        # Ki·ªÉm tra v√† k·∫øt th√∫c run hi·ªán t·∫°i n·∫øu c√≥
        # S·ª≠a ƒë·ªïi b·ªüi Grok 3: Lo·∫°i b·ªè session_state, ch·ªâ d√πng MLflow
        active_run = mlflow.active_run()
        if active_run:
            mlflow.end_run()

        with mlflow.start_run(run_name=f"{model_choice}_MNIST_{experiment_name}"):
            if model_choice in ["SVM (Support Vector Machine)", "Decision Tree"]:
                # Hu·∫•n luy·ªán m√¥ h√¨nh ph√¢n lo·∫°i
                if model_choice == "SVM (Support Vector Machine)":
                    model = SVC(**model_params, random_state=42)
                else:  # Decision Tree
                    model = DecisionTreeClassifier(**model_params, random_state=42)

                model.fit(X_train_scaled, y_train)
                train_acc = accuracy_score(y_train, model.predict(X_train_scaled))
                valid_acc = accuracy_score(y_valid, model.predict(X_valid_scaled))

                st.write(f"M√¥ h√¨nh ƒë√£ ch·ªçn: {model_choice}")
                st.write(f"Tham s·ªë: {model_params}")
                st.write(f"ƒê·ªô ch√≠nh x√°c hu·∫•n luy·ªán: {train_acc:.4f}")
                st.write(f"ƒê·ªô ch√≠nh x√°c validation: {valid_acc:.4f}")
                
                # Log m√¥ h√¨nh, metrics, v√† scaler v√†o MLflow
                mlflow.log_params(model_params)
                mlflow.log_param("model_type", model_choice)
                mlflow.log_metric("train_accuracy", train_acc)
                mlflow.log_metric("valid_accuracy", valid_acc)
                mlflow.sklearn.log_model(model, "model", input_example=X_train_scaled[:1])
                mlflow.sklearn.log_model(scaler, "scaler")  # Log scaler ƒë·ªÉ d√πng trong demo

            elif model_choice == "K-means (Clustering)":
                # Hu·∫•n luy·ªán m√¥ h√¨nh ph√¢n c·ª•m (kh√¥ng d√πng nh√£n)
                model = KMeans(**model_params, random_state=42)
                clusters = model.fit_predict(X_train_scaled)

                # ƒê√°nh gi√° b·∫±ng silhouette score (n·∫øu c√≥ nh√£n, ch·ªâ ƒë·ªÉ minh h·ªça)
                silhouette = silhouette_score(X_train_scaled, clusters) if len(np.unique(y_train)) > 1 else None
                st.write(f"M√¥ h√¨nh ƒë√£ ch·ªçn: {model_choice}")
                st.write(f"Tham s·ªë: {model_params}")
                st.write(f"Silhouette Score (n·∫øu c√≥): {silhouette:.4f}" if silhouette else "Kh√¥ng th·ªÉ t√≠nh Silhouette Score do nh√£n kh√¥ng ƒë·ªß ƒëa d·∫°ng.")
                st.write("L∆∞u √Ω: K-means kh√¥ng d·ª± ƒëo√°n nh√£n, ch·ªâ ph√¢n chia th√†nh c·ª•m.")

                # Log m√¥ h√¨nh, metrics, v√† model_choice v√†o MLflow
                mlflow.log_params(model_params)
                mlflow.log_param("model_type", model_choice)
                if silhouette:
                    mlflow.log_metric("silhouette_score", silhouette)
                mlflow.sklearn.log_model(model, "model", input_example=X_train_scaled[:1])

            elif model_choice == "DBSCAN (Clustering)":
                # Hu·∫•n luy·ªán m√¥ h√¨nh ph√¢n c·ª•m (kh√¥ng d√πng nh√£n)
                model = DBSCAN(**model_params)
                clusters = model.fit_predict(X_train_scaled)

                # ƒê√°nh gi√° b·∫±ng silhouette score (n·∫øu c√≥ nh√£n, ch·ªâ ƒë·ªÉ minh h·ªça)
                mask = clusters != -1  # Lo·∫°i b·ªè noise (-1)
                silhouette = silhouette_score(X_train_scaled[mask], clusters[mask]) if len(np.unique(clusters[mask])) > 1 else None
                st.write(f"M√¥ h√¨nh ƒë√£ ch·ªçn: {model_choice}")
                st.write(f"Tham s·ªë: {model_params}")
                st.write(f"Silhouette Score (n·∫øu c√≥): {silhouette:.4f}" if silhouette else "Kh√¥ng th·ªÉ t√≠nh Silhouette Score do nh√£n kh√¥ng ƒë·ªß ƒëa d·∫°ng.")
                st.write("L∆∞u √Ω: DBSCAN kh√¥ng d·ª± ƒëo√°n nh√£n, ch·ªâ ph√¢n chia th√†nh c·ª•m. Gi√° tr·ªã -1 l√† noise.")

                # Log m√¥ h√¨nh, metrics, v√† model_choice v√†o MLflow
                mlflow.log_params(model_params)
                mlflow.log_param("model_type", model_choice)
                if silhouette:
                    mlflow.log_metric("silhouette_score", silhouette)
                mlflow.sklearn.log_model(model, "model", input_example=X_train_scaled[:1])

            st.success(f"Hu·∫•n luy·ªán {model_choice} ho√†n t·∫•t v√† log v√†o MLflow th√†nh c√¥ng! ‚úÖ")

if __name__ == "__main__":
    train_mnist()