import streamlit as st
import numpy as np
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
import mlflow
import mlflow.sklearn
import os
import datetime
import time
import logging

# # T·∫Øt log kh√¥ng c·∫ßn thi·∫øt t·ª´ TensorFlow v√† MLflow
# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # T·∫Øt log TensorFlow
# logging.getLogger("mlflow").setLevel(logging.WARNING)  # Gi·∫£m log MLflow
def mlflow_input():
    DAGSHUB_MLFLOW_URI = 'https://dagshub.com/VietNam0410/ML_v3.mlflow'
    mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
    st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
    os.environ['MLFLOW_TRACKING_USERNAME'] = 'VietNam0410'
    os.environ['MLFLOW_TRACKING_PASSWORD'] = 'c9db6bdcca1dfed76d2af2cdb15a9277e6732d6b'
    os.environ["CUDA_VISIBLE_DEVICES"] = ""  # Ch·∫°y tr√™n CPU ƒë·ªÉ tr√°nh l·ªói CUDA
    return 'ML_v3'

@st.cache_resource
def get_scaler():
    return StandardScaler()

@st.cache_resource
def get_model(model_choice, **params):
    if model_choice == 'SVM':
        return SVC(**params)
    else:
        return DecisionTreeClassifier(**params)


def train_mnist(X_full, y_full):
    st.header('Hu·∫•n luy·ªán M√¥ h√¨nh Nh·∫≠n di·ªán tr√™n MNIST üßÆ')
    if mlflow.active_run():
        mlflow.end_run()

    DAGSHUB_REPO = mlflow_input()
    if DAGSHUB_REPO is None:
        st.error('L·ªói k·∫øt n·ªëi MLflow.')
        return

    mlflow.set_experiment('MNIST_Training')

    total_samples = len(X_full)
    st.subheader('Chia t·∫≠p d·ªØ li·ªáu MNIST üîÄ')
    max_samples = st.slider(
        'S·ªë m·∫´u t·ªëi ƒëa',
        1000, 70000, min(10000, total_samples),
        step=1000, key='max_samples_ex2',
        help='S·ªë l∆∞·ª£ng m·∫´u d·ªØ li·ªáu s·∫Ω ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ hu·∫•n luy·ªán. Gi√° tr·ªã l·ªõn h∆°n s·∫Ω c·∫£i thi·ªán ƒë·ªô ch√≠nh x√°c nh∆∞ng l√†m ch·∫≠m qu√° tr√¨nh hu·∫•n luy·ªán.'
    )
    if max_samples < total_samples:
        indices = np.random.choice(total_samples, max_samples, replace=False)
        X_full = X_full[indices]
        y_full = y_full[indices]
    if max_samples > 50000:
        st.warning('S·ªë m·∫´u l·ªõn (>50,000) c√≥ th·ªÉ l√†m ch·∫≠m hu·∫•n luy·ªán.')

    test_size = st.slider(
        'T·ª∑ l·ªá t·∫≠p ki·ªÉm tra (%)',
        10, 50, 20, step=5, key='test_size_ex2',
        help='Ph·∫ßn trƒÉm d·ªØ li·ªáu ƒë∆∞·ª£c s·ª≠ d·ª•ng cho t·∫≠p ki·ªÉm tra (test set). Ph·∫ßn c√≤n l·∫°i s·∫Ω ƒë∆∞·ª£c chia th√†nh t·∫≠p hu·∫•n luy·ªán v√† t·∫≠p validation.'
    ) / 100
    train_size_relative = st.slider(
        'T·ª∑ l·ªá t·∫≠p hu·∫•n luy·ªán (%)',
        50, 90, 70, step=5, key='train_size_ex2',
        help='Ph·∫ßn trƒÉm d·ªØ li·ªáu (trong ph·∫ßn kh√¥ng thu·ªôc t·∫≠p ki·ªÉm tra) ƒë∆∞·ª£c d√πng ƒë·ªÉ hu·∫•n luy·ªán. Ph·∫ßn c√≤n l·∫°i s·∫Ω l√† t·∫≠p validation.'
    ) / 100
    val_size_relative = 1 - train_size_relative

    X_remaining, X_test, y_remaining, y_test = train_test_split(
        X_full, y_full, test_size=test_size, random_state=42, stratify=y_full
    )
    X_train, X_valid, y_train, y_valid = train_test_split(
        X_remaining, y_remaining, train_size=train_size_relative, random_state=42, stratify=y_remaining
    )

    st.write(f'T·ªïng s·ªë m·∫´u: {max_samples}')
    st.write(f'T·ª∑ l·ªá: Hu·∫•n luy·ªán {train_size_relative*100:.1f}%, Validation {val_size_relative*100:.1f}%, Ki·ªÉm tra {test_size*100:.1f}%')
    st.write(f'T·∫≠p hu·∫•n luy·ªán: {len(X_train)} m·∫´u, Validation: {len(X_valid)} m·∫´u, Ki·ªÉm tra: {len(X_test)} m·∫´u')

    X_train_flat = X_train.reshape(X_train.shape[0], -1)
    X_valid_flat = X_valid.reshape(X_valid.shape[0], -1)
    X_test_flat = X_test.reshape(X_test.shape[0], -1)

    scaler = get_scaler()
    X_train_scaled = scaler.fit_transform(X_train_flat)
    X_valid_scaled = scaler.transform(X_valid_flat)
    X_test_scaled = scaler.transform(X_test_flat)

    st.subheader('Hu·∫•n luy·ªán M√¥ h√¨nh üéØ')
    model_choice = st.selectbox(
        'Ch·ªçn thu·∫≠t to√°n',
        ['SVM', 'Decision Tree'],
        key='model_choice_ex2',
        help='Ch·ªçn thu·∫≠t to√°n ph√¢n lo·∫°i: SVM (ph√¢n lo·∫°i d·ª±a tr√™n ranh gi·ªõi t·ªëi ∆∞u) ho·∫∑c Decision Tree (ph√¢n lo·∫°i d·ª±a tr√™n c√¢y quy·∫øt ƒë·ªãnh).'
    )
    model_params = {}
    if model_choice == 'SVM':
        kernel = st.selectbox(
            'Kernel',
            ['linear', 'rbf', 'poly'],
            index=0, key='svm_kernel_ex2',
            help='Lo·∫°i kernel cho SVM: "linear" (tuy·∫øn t√≠nh, nhanh nh·∫•t), "rbf" (phi tuy·∫øn t√≠nh, ch√≠nh x√°c h∆°n nh∆∞ng ch·∫≠m h∆°n), "poly" (ƒëa th·ª©c, ch·∫≠m v√† ph·ª©c t·∫°p).'
        )
        model_params = {'kernel': kernel, 'probability': True, 'random_state': 42}
    else:
        max_depth = st.slider(
            'ƒê·ªô s√¢u t·ªëi ƒëa',
            3, 20, 10, step=1, key='dt_max_depth_ex2',
            help='S·ªë l·ªõp t·ªëi ƒëa c·ªßa c√¢y quy·∫øt ƒë·ªãnh. Gi√° tr·ªã l·ªõn h∆°n l√†m tƒÉng ƒë·ªô ch√≠nh x√°c nh∆∞ng c√≥ th·ªÉ d·∫´n ƒë·∫øn overfitting v√† ch·∫≠m h∆°n.'
        )
        model_params = {
            'max_depth': max_depth,
            'random_state': 42
        }

    run_name = st.text_input(
        'Nh·∫≠p t√™n Run ID',
        value='', key='run_name_ex2',
        help='T√™n ƒë·ªÉ nh·∫≠n di·ªán l·∫ßn hu·∫•n luy·ªán n√†y tr√™n MLflow. N·∫øu ƒë·ªÉ tr·ªëng, h·ªá th·ªëng s·∫Ω t·ª± t·∫°o t√™n d·ª±a tr√™n th·ªùi gian.'
    )
    if not run_name.strip():
        timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')
        run_name = f'MNIST_{model_choice}_{timestamp}'

    if st.button('Hu·∫•n luy·ªán', key='train_button_ex2'):
        # Kh·ªüi t·∫°o thanh ti·∫øn tr√¨nh
        progress = st.progress(0)
        status_text = st.empty()

        # B·∫Øt ƒë·∫ßu ƒëo th·ªùi gian
        start_time = datetime.datetime.now()

        # B∆∞·ªõc 1: Chu·∫©n h√≥a d·ªØ li·ªáu (30% ti·∫øn tr√¨nh)
        status_text.text("Chu·∫©n h√≥a d·ªØ li·ªáu... 30%")
        progress.progress(0.3)
        time.sleep(0.1)  # Gi·∫£ l·∫≠p th·ªùi gian x·ª≠ l√Ω
        scaler = get_scaler()
        X_train_scaled = scaler.fit_transform(X_train_flat)
        X_valid_scaled = scaler.transform(X_valid_flat)
        X_test_scaled = scaler.transform(X_test_flat)

        # B∆∞·ªõc 2: Hu·∫•n luy·ªán m√¥ h√¨nh (80% ti·∫øn tr√¨nh)
        status_text.text("Hu·∫•n luy·ªán m√¥ h√¨nh... 80%")
        progress.progress(0.8)
        time.sleep(0.1)  # Gi·∫£ l·∫≠p th·ªùi gian x·ª≠ l√Ω
        model = get_model(model_choice, **model_params)
        model.fit(X_train_scaled, y_train)

        # B∆∞·ªõc 3: ƒê√°nh gi√° v√† ho√†n t·∫•t (100% ti·∫øn tr√¨nh)
        status_text.text("ƒê√°nh gi√° m√¥ h√¨nh... 100%")
        progress.progress(1.0)
        time.sleep(0.1)  # Gi·∫£ l·∫≠p th·ªùi gian x·ª≠ l√Ω
        train_acc = accuracy_score(y_train, model.predict(X_train_scaled))
        valid_acc = accuracy_score(y_valid, model.predict(X_valid_scaled))
        test_acc = accuracy_score(y_test, model.predict(X_test_scaled))

        # T√≠nh th·ªùi gian hu·∫•n luy·ªán
        training_duration = (datetime.datetime.now() - start_time).total_seconds()
        log_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')

        # Log k·∫øt qu·∫£ v√†o MLflow
        with mlflow.start_run(run_name=run_name):
            mlflow.log_param('model_type', model_choice)
            mlflow.log_params(model_params)
            mlflow.log_param('log_time', log_time)
            mlflow.log_metric('train_accuracy', train_acc)
            mlflow.log_metric('valid_accuracy', valid_acc)
            mlflow.log_metric('test_accuracy', test_acc)
            mlflow.log_metric('training_duration', training_duration)
            mlflow.sklearn.log_model(model, 'model', input_example=X_train_scaled[:1])  # ƒê·∫£m b·∫£o input_example h·ª£p l·ªá
            run_id = mlflow.active_run().info.run_id

        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        status_text.text("Hu·∫•n luy·ªán ho√†n t·∫•t!")
        st.write(f'**M√¥ h√¨nh**: {model_choice}')
        st.write(f'**ƒê·ªô ch√≠nh x√°c**: Train: {train_acc:.4f}, Valid: {valid_acc:.4f}, Test: {test_acc:.4f}')
        st.write(f'Th·ªùi gian hu·∫•n luy·ªán: {training_duration:.2f} gi√¢y')
        st.write(f'Th·ªùi gian log: {log_time}')
        st.success(f'Hu·∫•n luy·ªán ho√†n t·∫•t! Run ID: {run_id}')

if __name__ == "__main__":
    from sklearn.datasets import fetch_openml
    X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)
    X = X.astype(np.float32)
    y = y.astype(np.int64)
    train_mnist(X, y)