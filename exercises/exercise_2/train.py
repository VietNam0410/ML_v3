import streamlit as st
import numpy as np
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.cluster import KMeans, DBSCAN
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, silhouette_score  # D√πng silhouette_score cho clustering
from sklearn.preprocessing import StandardScaler, LabelEncoder

def train_mnist():
    st.header("Hu·∫•n luy·ªán M√¥ h√¨nh Nh·∫≠n di·ªán Ch·ªØ s·ªë MNIST üßÆ")

    # Cho ng∆∞·ªùi d√πng ƒë·∫∑t t√™n Experiment (gi·ªù ch·ªâ ƒë·ªÉ hi·ªÉn th·ªã, kh√¥ng d√πng MLflow)
    experiment_name = st.text_input("Nh·∫≠p T√™n Experiment cho Hu·∫•n luy·ªán", value="MNIST_Training")
    
    # Ki·ªÉm tra d·ªØ li·ªáu ƒë√£ ti·ªÅn x·ª≠ l√Ω trong session
    if 'processed_mnist' not in st.session_state:
        st.error("D·ªØ li·ªáu MNIST ƒë√£ x·ª≠ l√Ω kh√¥ng t√¨m th·∫•y. Vui l√≤ng ho√†n t·∫•t ti·ªÅn x·ª≠ l√Ω trong 'Ti·ªÅn x·ª≠ l√Ω D·ªØ li·ªáu MNIST' tr∆∞·ªõc.")
        return
    mnist_data = st.session_state['processed_mnist']

    st.subheader("D·ªØ li·ªáu MNIST ƒë√£ x·ª≠ l√Ω üìù")
    st.write("ƒê√¢y l√† d·ªØ li·ªáu sau c√°c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω trong 'Ti·ªÅn x·ª≠ l√Ω D·ªØ li·ªáu MNIST':")
    st.write(f"S·ªë l∆∞·ª£ng m·∫´u hu·∫•n luy·ªán: {len(mnist_data['X_train'])}")
    st.write(f"S·ªë l∆∞·ª£ng m·∫´u validation: {len(mnist_data.get('X_valid', []))}")
    st.write(f"S·ªë l∆∞·ª£ng m·∫´u ki·ªÉm tra: {len(mnist_data['X_test'])}")

    # Chu·∫©n b·ªã d·ªØ li·ªáu: Flatten h√¨nh ·∫£nh 28x28 th√†nh vector 784 chi·ªÅu
    X_train = mnist_data['X_train'].reshape(-1, 28 * 28)
    y_train = mnist_data['y_train']
    X_valid = mnist_data.get('X_valid', mnist_data['X_test']).reshape(-1, 28 * 28)
    y_valid = mnist_data.get('y_valid', mnist_data['y_test'])
    X_test = mnist_data['X_test'].reshape(-1, 28 * 28)

    # Chu·∫©n h√≥a d·ªØ li·ªáu cho c√°c m√¥ h√¨nh (SVM, Decision Tree, K-means, DBSCAN)
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_valid_scaled = scaler.transform(X_valid)
    X_test_scaled = scaler.transform(X_test)

    # X√¢y d·ª±ng v√† hu·∫•n luy·ªán m√¥ h√¨nh
    st.subheader("X√¢y d·ª±ng v√† Hu·∫•n luy·ªán M√¥ h√¨nh üéØ")
    model_choice = st.selectbox(
        "Ch·ªçn lo·∫°i m√¥ h√¨nh",
        ["SVM (Support Vector Machine)", "Decision Tree", "K-means (Clustering)", "DBSCAN (Clustering)"]
    )

    # Tham s·ªë hu·∫•n luy·ªán cho t·ª´ng m√¥ h√¨nh
    if model_choice == "SVM (Support Vector Machine)":
        kernel = st.selectbox("Ch·ªçn kernel SVM", ["linear", "rbf", "poly"], index=1)
        C = st.slider("C (Regularization parameter)", 0.1, 10.0, 1.0, step=0.1)
        model_params = {"kernel": kernel, "C": C}
    elif model_choice == "Decision Tree":
        max_depth = st.slider("ƒê·ªô s√¢u t·ªëi ƒëa", 1, 20, 10, step=1)
        min_samples_split = st.slider("S·ªë m·∫´u t·ªëi thi·ªÉu ƒë·ªÉ chia", 2, 20, 2, step=1)
        model_params = {"max_depth": max_depth, "min_samples_split": min_samples_split}
    elif model_choice == "K-means (Clustering)":
        n_clusters = st.slider("S·ªë c·ª•m", 2, 20, 10, step=1)
        model_params = {"n_clusters": n_clusters}
    else:  # DBSCAN
        eps = st.slider("Epsilon (kho·∫£ng c√°ch t·ªëi ƒëa)", 0.1, 1.0, 0.5, step=0.1)
        min_samples = st.slider("S·ªë m·∫´u t·ªëi thi·ªÉu", 1, 10, 5, step=1)
        model_params = {"eps": eps, "min_samples": min_samples}

    if st.button("Hu·∫•n luy·ªán m√¥ h√¨nh"):
        if model_choice in ["SVM (Support Vector Machine)", "Decision Tree"]:
            # Hu·∫•n luy·ªán m√¥ h√¨nh ph√¢n lo·∫°i
            if model_choice == "SVM (Support Vector Machine)":
                model = SVC(**model_params, random_state=42)
            else:  # Decision Tree
                model = DecisionTreeClassifier(**model_params, random_state=42)

            model.fit(X_train_scaled, y_train)
            train_acc = accuracy_score(y_train, model.predict(X_train_scaled))
            valid_acc = accuracy_score(y_valid, model.predict(X_valid_scaled))

            st.write(f"M√¥ h√¨nh ƒë√£ ch·ªçn: {model_choice}")
            st.write(f"Tham s·ªë: {model_params}")
            st.write(f"ƒê·ªô ch√≠nh x√°c hu·∫•n luy·ªán: {train_acc:.4f}")
            st.write(f"ƒê·ªô ch√≠nh x√°c validation: {valid_acc:.4f}")
            
            # L∆∞u m√¥ h√¨nh trong session
            # S·ª≠a ƒë·ªïi b·ªüi Grok 3: Lo·∫°i b·ªè MLflow, l∆∞u trong session_state
            st.session_state['mnist_model'] = model
            st.session_state['model_params'] = model_params
            st.session_state['training_metrics'] = {"train_accuracy": train_acc, "valid_accuracy": valid_acc}
            st.success(f"Hu·∫•n luy·ªán {model_choice} ho√†n t·∫•t v√† l∆∞u trong session! ‚úÖ")
        
        elif model_choice == "K-means (Clustering)":
            # Hu·∫•n luy·ªán m√¥ h√¨nh ph√¢n c·ª•m (kh√¥ng d√πng nh√£n)
            model = KMeans(**model_params, random_state=42)
            clusters = model.fit_predict(X_train_scaled)

            # ƒê√°nh gi√° b·∫±ng silhouette score (n·∫øu c√≥ nh√£n, ch·ªâ ƒë·ªÉ minh h·ªça)
            silhouette = silhouette_score(X_train_scaled, clusters) if len(np.unique(y_train)) > 1 else None
            st.write(f"M√¥ h√¨nh ƒë√£ ch·ªçn: {model_choice}")
            st.write(f"Tham s·ªë: {model_params}")
            st.write(f"Silhouette Score (n·∫øu c√≥): {silhouette:.4f}" if silhouette else "Kh√¥ng th·ªÉ t√≠nh Silhouette Score do nh√£n kh√¥ng ƒë·ªß ƒëa d·∫°ng.")
            st.write("L∆∞u √Ω: K-means kh√¥ng d·ª± ƒëo√°n nh√£n, ch·ªâ ph√¢n chia th√†nh c·ª•m.")

            # L∆∞u m√¥ h√¨nh trong session
            # S·ª≠a ƒë·ªïi b·ªüi Grok 3: Lo·∫°i b·ªè MLflow, l∆∞u trong session_state
            st.session_state['mnist_model'] = model
            st.session_state['model_params'] = model_params
            st.session_state['clustering_result'] = clusters
            st.success(f"Hu·∫•n luy·ªán {model_choice} ho√†n t·∫•t v√† l∆∞u trong session! ‚úÖ")

        elif model_choice == "DBSCAN (Clustering)":
            # Hu·∫•n luy·ªán m√¥ h√¨nh ph√¢n c·ª•m (kh√¥ng d√πng nh√£n)
            model = DBSCAN(**model_params)
            clusters = model.fit_predict(X_train_scaled)

            # ƒê√°nh gi√° b·∫±ng silhouette score (n·∫øu c√≥ nh√£n, ch·ªâ ƒë·ªÉ minh h·ªça)
            mask = clusters != -1  # Lo·∫°i b·ªè noise (-1)
            silhouette = silhouette_score(X_train_scaled[mask], clusters[mask]) if len(np.unique(clusters[mask])) > 1 else None
            st.write(f"M√¥ h√¨nh ƒë√£ ch·ªçn: {model_choice}")
            st.write(f"Tham s·ªë: {model_params}")
            st.write(f"Silhouette Score (n·∫øu c√≥): {silhouette:.4f}" if silhouette else "Kh√¥ng th·ªÉ t√≠nh Silhouette Score do nh√£n kh√¥ng ƒë·ªß ƒëa d·∫°ng.")
            st.write("L∆∞u √Ω: DBSCAN kh√¥ng d·ª± ƒëo√°n nh√£n, ch·ªâ ph√¢n chia th√†nh c·ª•m. Gi√° tr·ªã -1 l√† noise.")

            # L∆∞u m√¥ h√¨nh trong session
            # S·ª≠a ƒë·ªïi b·ªüi Grok 3: Lo·∫°i b·ªè MLflow, l∆∞u trong session_state
            st.session_state['mnist_model'] = model
            st.session_state['model_params'] = model_params
            st.session_state['clustering_result'] = clusters
            st.success(f"Hu·∫•n luy·ªán {model_choice} ho√†n t·∫•t v√† l∆∞u trong session! ‚úÖ")

if __name__ == "__main__":
    train_mnist()