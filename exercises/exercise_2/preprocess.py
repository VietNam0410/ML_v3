import streamlit as st
import numpy as np
import openml
from sklearn.model_selection import train_test_split
from tensorflow.keras.datasets import mnist  # Backup n·∫øu OpenML kh√¥ng t·∫£i ƒë∆∞·ª£c

# S·ª≠ d·ª•ng st.cache_data ƒë·ªÉ cache d·ªØ li·ªáu, tƒÉng t·ªëc ƒë·ªô load
@st.cache_data
def load_mnist_from_openml():
    try:
        # T·∫£i d·ªØ li·ªáu MNIST t·ª´ OpenML (ID dataset MNIST l√† 554)
        dataset = openml.datasets.get_dataset(554)
        X, y, _, _ = dataset.get_data(target='class')
        
        # Chuy·ªÉn ƒë·ªïi X (DataFrame) th√†nh m·∫£ng numpy v√† chu·∫©n h√≥a (28x28x1)
        X = X.values.reshape(-1, 28, 28, 1) / 255.0  # S·ª≠ d·ª•ng .values ƒë·ªÉ l·∫•y m·∫£ng numpy t·ª´ DataFrame
        y = y.astype(np.int32)
        
        return X, y
    except Exception as e:
        st.error(f"Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu t·ª´ OpenML. S·ª≠ d·ª•ng d·ªØ li·ªáu t·ª´ TensorFlow: {str(e)}")
        # Fallback: T·∫£i t·ª´ TensorFlow n·∫øu OpenML th·∫•t b·∫°i
        (X_train, y_train), (X_test, y_test) = mnist.load_data()
        X = np.concatenate([X_train, X_test], axis=0) / 255.0
        y = np.concatenate([y_train, y_test], axis=0)
        return X.reshape(-1, 28, 28, 1), y

def preprocess_mnist():
    st.header("Ti·ªÅn x·ª≠ l√Ω D·ªØ li·ªáu MNIST Ch·ªØ s·ªë Vi·∫øt Tay üñåÔ∏è")

    # Cho ng∆∞·ªùi d√πng ƒë·∫∑t t√™n Experiment (ch·ªâ ƒë·ªÉ hi·ªÉn th·ªã)
    experiment_name = st.text_input("Nh·∫≠p t√™n Experiment cho ti·ªÅn x·ª≠ l√Ω", value="MNIST_Preprocessing")

    # T·∫£i d·ªØ li·ªáu MNIST t·ª´ OpenML (s·ª≠ d·ª•ng cache)
    if 'X_full' not in st.session_state or 'y_full' not in st.session_state:
        st.session_state['X_full'], st.session_state['y_full'] = load_mnist_from_openml()
        st.success("D·ªØ li·ªáu MNIST ƒë√£ ƒë∆∞·ª£c t·∫£i v√† chu·∫©n h√≥a th√†nh c√¥ng! ‚úÖ")

    # Ki·ªÉm tra d·ªØ li·ªáu
    X_full = st.session_state['X_full']
    y_full = st.session_state['y_full']
    total_samples = len(X_full)

    # Hi·ªÉn th·ªã th√¥ng tin d·ªØ li·ªáu ƒë·∫ßy ƒë·ªß (kh√¥ng hi·ªÉn th·ªã h√¨nh ·∫£nh)
    st.subheader("Th√¥ng tin D·ªØ li·ªáu MNIST ƒê·∫ßy ƒë·ªß üîç")
    st.write(f"T·ªïng s·ªë l∆∞·ª£ng m·∫´u: {total_samples}")

    # Cho ph√©p ng∆∞·ªùi d√πng ch·ªçn s·ªë l∆∞·ª£ng m·∫´u v√† t·ª∑ l·ªá chia
    st.subheader("Chia t√°ch D·ªØ li·ªáu (T√πy ch·ªçn) üîÄ")
    max_samples = st.slider("Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u t·ªëi ƒëa (0 ƒë·ªÉ d√πng to√†n b·ªô)", 0, total_samples, total_samples, step=100)
    
    if max_samples == 0:
        max_samples = total_samples
    elif max_samples > total_samples:
        st.error(f"S·ªë l∆∞·ª£ng m·∫´u ({max_samples}) v∆∞·ª£t qu√° t·ªïng s·ªë m·∫´u c√≥ s·∫µn ({total_samples}). ƒê·∫∑t l·∫°i v·ªÅ {total_samples}.")
        max_samples = total_samples

    train_size = st.slider("Ch·ªçn k√≠ch th∆∞·ªõc t·∫≠p hu·∫•n luy·ªán (%)", min_value=10, max_value=90, value=70, step=5) / 100
    val_size = st.slider("Ch·ªçn k√≠ch th∆∞·ªõc t·∫≠p validation (%)", min_value=0, max_value=30, value=15, step=5) / 100
    test_size = 1 - train_size - val_size  # T√≠nh k√≠ch th∆∞·ªõc t·∫≠p ki·ªÉm tra

    if test_size < 0:
        st.error("T·ªïng k√≠ch th∆∞·ªõc t·∫≠p hu·∫•n luy·ªán v√† validation kh√¥ng ƒë∆∞·ª£c v∆∞·ª£t qu√° 100%. Vui l√≤ng ƒëi·ªÅu ch·ªânh l·∫°i.")
    else:
        if st.button("Chia d·ªØ li·ªáu"):
            # L·∫•y m·∫´u ng·∫´u nhi√™n n·∫øu max_samples < total_samples
            if max_samples < total_samples:
                indices = np.random.choice(total_samples, max_samples, replace=False)
                X_subset = X_full[indices]
                y_subset = y_full[indices]
            else:
                X_subset = X_full
                y_subset = y_full

            # Chia d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán, validation, v√† ki·ªÉm tra
            X_temp, X_test, y_temp, y_test = train_test_split(X_subset, y_subset, test_size=test_size, random_state=42)
            X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=val_size/(train_size+val_size), random_state=42)

            # Hi·ªÉn th·ªã k·∫øt qu·∫£ chia d·ªØ li·ªáu
            st.success(f"ƒê√£ chia d·ªØ li·ªáu v·ªõi s·ªë l∆∞·ª£ng m·∫´u: {max_samples}. K√≠ch th∆∞·ªõc: Hu·∫•n luy·ªán {train_size*100:.1f}%, Validation {val_size*100:.1f}%, Ki·ªÉm tra {test_size*100:.1f}%! ‚úÖ")

            st.write(f"T·∫≠p hu·∫•n luy·ªán: {len(X_train)} m·∫´u")
            st.write(f"T·∫≠p validation: {len(X_valid)} m·∫´u")
            st.write(f"T·∫≠p ki·ªÉm tra: {len(X_test)} m·∫´u")

            # L∆∞u d·ªØ li·ªáu v√†o session_state ƒë·ªÉ s·ª≠ d·ª•ng trong train.py
            st.session_state['mnist_data'] = {
                'X_train': X_train,
                'y_train': y_train,
                'X_valid': X_valid,
                'y_valid': y_valid,
                'X_test': X_test,
                'y_test': y_test
            }

if __name__ == "__main__":
    preprocess_mnist()