import streamlit as st
import pandas as pd
import mlflow
from mlflow.tracking import MlflowClient
import os
import logging
import numpy as np  # Th√™m import numpy
import datetime

# Thi·∫øt l·∫≠p logging ƒë·ªÉ debug n·∫øu c·∫ßn
logging.getLogger("mlflow").setLevel(logging.INFO)

# Thi·∫øt l·∫≠p MLflow v√† DagsHub
DAGSHUB_MLFLOW_URI = "https://dagshub.com/VietNam0410/ML_v3.mlflow"
mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
os.environ["MLFLOW_TRACKING_USERNAME"] = "VietNam0410"
os.environ["MLFLOW_TRACKING_PASSWORD"] = "c9db6bdcca1dfed76d2af2cdb15a9277e6732d6b"

# H√†m hi·ªÉn th·ªã v√† x√≥a log t·ª´ experiment
@st.cache_data
def display_logs(_client, experiment_name):
    experiment = _client.get_experiment_by_name(experiment_name)
    if not experiment:
        st.warning(f"Ch∆∞a c√≥ experiment '{experiment_name}'. S·∫Ω t·∫°o khi c√≥ log ƒë·∫ßu ti√™n.")
        return None, None
    
    runs = _client.search_runs(experiment_ids=[experiment.experiment_id])
    if not runs:
        st.warning(f"Kh√¥ng c√≥ log n√†o trong experiment '{experiment_name}'.")
        return None, None
    
    data = []
    for run in runs:
        run_name = run.data.tags.get("mlflow.runName", run.info.run_id)
        method = run.data.params.get("method", "N/A")
        n_components = run.data.params.get("n_components", "N/A")
        source = run.data.params.get("source", "N/A")
        timestamp = run.data.params.get("timestamp", "N/A")
        confidence = run.data.metrics.get("confidence", np.nan)
        explained_variance = run.data.metrics.get("explained_variance_ratio", np.nan)
        position = [run.data.metrics.get(f"position_{i}", np.nan) for i in range(3)]
        data.append({
            "T√™n Run": run_name,
            "Ph∆∞∆°ng ph√°p": method,
            "S·ªë chi·ªÅu": n_components,
            "Ngu·ªìn": source,
            "Th·ªùi gian": timestamp,
            "V·ªã tr√≠": str(position[:int(n_components) if n_components != "N/A" else 2]),  # Ch·ªâ l·∫•y s·ªë chi·ªÅu t∆∞∆°ng ·ª©ng
            "ƒê·ªô tin c·∫≠y": confidence,  # S·ª≠ d·ª•ng np.nan thay v√¨ "N/A"
            "Ph∆∞∆°ng sai": explained_variance,  # S·ª≠ d·ª•ng np.nan thay v√¨ "N/A"
            "Run ID": run.info.run_id
        })
    
    df = pd.DataFrame(data, dtype='object')
    st.dataframe(df, hide_index=True, width=1200)
    return df, runs

# H√†m x√≥a log theo l·ª±a ch·ªçn
def clear_selected_logs(client, selected_runs):
    if not selected_runs:
        st.warning("Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt run ƒë·ªÉ x√≥a.")
        return
    
    with st.spinner("ƒêang x√≥a c√°c run ƒë√£ ch·ªçn..."):
        for run_id in selected_runs:
            client.delete_run(run_id)
        st.success(f"ƒê√£ x√≥a {len(selected_runs)} run th√†nh c√¥ng!")
    st.rerun()

# Giao di·ªán Streamlit (ch·ªâ hi·ªÉn th·ªã log hu·∫•n luy·ªán)
def view_logs_app():
    st.title("üìú Xem v√† Qu·∫£n l√Ω Log Hu·∫•n luy·ªán Gi·∫£m Chi·ªÅu MNIST")

    # T·∫°o client MLflow
    client = MlflowClient()

    # Ch·ªâ hi·ªÉn th·ªã log t·ª´ MNIST_Dimensionality_Reduction (hu·∫•n luy·ªán)
    st.subheader("Log t·ª´ Experiment Hu·∫•n luy·ªán (MNIST_Dimensionality_Reduction)")
    with st.spinner("ƒêang t·∫£i log hu·∫•n luy·ªán..."):
        train_df, train_runs = display_logs(client, "MNIST_Dimensionality_Reduction")

    if train_df is not None and not train_df.empty:
        # L·∫•y danh s√°ch Run ID t·ª´ dataframe hu·∫•n luy·ªán
        train_run_ids = train_df["Run ID"].tolist()
        # Cho ph√©p ng∆∞·ªùi d√πng ch·ªçn run ƒë·ªÉ x√≥a
        selected_train_runs = st.multiselect("Ch·ªçn c√°c run hu·∫•n luy·ªán ƒë·ªÉ x√≥a", train_run_ids)
        if st.button("X√≥a c√°c run hu·∫•n luy·ªán ƒë√£ ch·ªçn", key="delete_train_runs"):
            clear_selected_logs(client, selected_train_runs)

    # Th√™m n√∫t l√†m m·ªõi cache v·ªõi key duy nh·∫•t
    if st.button("üîÑ L√†m m·ªõi d·ªØ li·ªáu", key=f"refresh_data_{datetime.datetime.now().microsecond}"):
        st.cache_data.clear()
        st.rerun()

# H√†m ch√≠nh
if __name__ == "__main__":
    view_logs_app()