import streamlit as st
import numpy as np
import pandas as pd
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from tensorflow.keras.datasets import mnist
import openml
import plotly.express as px
import mlflow
import os
import dagshub
import datetime
from sklearn.preprocessing import StandardScaler

# Thi·∫øt l·∫≠p MLflow v√† DagsHub
DAGSHUB_MLFLOW_URI = "https://dagshub.com/VietNam0410/ML_v3.mlflow"
mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
os.environ["MLFLOW_TRACKING_USERNAME"] = "VietNam0410"
os.environ["MLFLOW_TRACKING_PASSWORD"] = "c9db6bdcca1dfed76d2af2cdb15a9277e6732d6b"

# Cache d·ªØ li·ªáu MNIST ƒë·ªÉ t·ªëi ∆∞u h√≥a
@st.cache_data(ttl=86400)  # L√†m m·ªõi sau 24 gi·ªù
def load_mnist(max_samples=10000):  # Gi·∫£m m·∫∑c ƒë·ªãnh xu·ªëng 10,000 ƒë·ªÉ tƒÉng t·ªëc
    with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu MNIST..."):
        try:
            dataset = openml.datasets.get_dataset(554)
            X, y, _, _ = dataset.get_data(target='class')
            X = X.values.reshape(-1, 28 * 28) / 255.0  # L√†m ph·∫≥ng v√† chu·∫©n h√≥a
            y = y.astype(np.int32)
        except Exception as e:
            st.error(f"Kh√¥ng th·ªÉ t·∫£i t·ª´ OpenML: {str(e)}. S·ª≠ d·ª•ng TensorFlow.")
            (X_train, y_train), (X_test, y_test) = mnist.load_data()
            X = np.concatenate([X_train, X_test], axis=0) / 255.0
            y = np.concatenate([y_train, y_test], axis=0)
            X = X.reshape(-1, 28 * 28)
        if max_samples < len(X):
            indices = np.random.choice(len(X), max_samples, replace=False)
            X, y = X[indices], y[indices]
        return X, y

# Cache scaler ƒë·ªÉ t√°i s·ª≠ d·ª•ng
@st.cache_resource
def get_scaler():
    return StandardScaler()

# H√†m hu·∫•n luy·ªán v√† gi·∫£m chi·ªÅu (t·ªëi ∆∞u h√≥a t·ªëc ƒë·ªô)
def train_dimensionality_reduction(X, y, method, n_components):
    scaler = get_scaler()
    X_scaled = scaler.fit_transform(X)
    
    start_time = datetime.datetime.now()
    if method == "PCA":
        model = PCA(n_components=n_components)
    elif method == "t-SNE":
        model = TSNE(n_components=n_components, perplexity=15, n_iter=500, random_state=42, n_jobs=-1)  # TƒÉng t·ªëc t-SNE
    
    with st.spinner(f"ƒêang gi·∫£m chi·ªÅu b·∫±ng {method}..."):
        X_reduced = model.fit_transform(X_scaled)
    
    end_time = datetime.datetime.now()
    duration = (end_time - start_time).total_seconds()
    
    return X_reduced, model, duration

# H√†m tr·ª±c quan h√≥a k·∫øt qu·∫£ (t∆∞∆°ng t√°c 2D/3D v·ªõi Plotly, b·ªè ƒë·ªô tin c·∫≠y)
def visualize_reduction(X_reduced, y, method, n_components):
    if n_components == 2:
        fig = px.scatter(
            X_reduced, x=0, y=1, color=y, labels={'color': 'Nh√£n (0-9)'},
            title=f"Tr·ª±c quan h√≥a {method} (2D)", color_continuous_scale='Viridis'
        )
    else:  # n_components == 3
        fig = px.scatter_3d(
            X_reduced, x=0, y=1, z=2, color=y, labels={'color': 'Nh√£n (0-9)'},
            title=f"Tr·ª±c quan h√≥a {method} (3D)", color_continuous_scale='Viridis'
        )
    
    st.plotly_chart(fig, use_container_width=True)

# H√†m log k·∫øt qu·∫£ v√†o MLflow (ch·ªâ gi·ªØ c√°c th√¥ng tin c·∫ßn thi·∫øt)
def log_results(method, n_components, duration, X, y, X_reduced, model):
    experiment_name = "MNIST_Dimensionality_Reduction"
    mlflow.set_experiment(experiment_name)
    
    timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    run_name = f"{method}_n={n_components}_{timestamp.replace(' ', '_').replace(':', '-')}"
    
    with mlflow.start_run(run_name=run_name) as run:
        mlflow.log_param("method", method)
        mlflow.log_param("n_components", n_components)
        mlflow.log_param("max_samples", len(X))
        mlflow.log_param("timestamp", timestamp)
        mlflow.log_metric("duration_seconds", duration)
        
        if method == "PCA":
            mlflow.log_metric("explained_variance_ratio", np.sum(model.explained_variance_ratio_))
        
        # Ch·ªâ log model, kh√¥ng log scaler ƒë·ªÉ tr√°nh l·ªói
        mlflow.sklearn.log_model(model, "model", input_example=X[:1])
        
        run_id = run.info.run_id
        mlflow_uri = DAGSHUB_MLFLOW_URI
        st.success(f"ƒê√£ log k·∫øt qu·∫£ v√†o MLflow! (Run: {run_name}, ID: {run_id}, Th·ªùi gian: {timestamp})")
        st.markdown(f"Xem chi ti·∫øt t·∫°i: [DagsHub MLflow]({mlflow_uri})")

# Giao di·ªán Streamlit
def dimensionality_reduction_app():
    st.title("üåê Gi·∫£m Chi·ªÅu D·ªØ Li·ªáu MNIST v·ªõi PCA v√† t-SNE")

    # T·∫£i d·ªØ li·ªáu v·ªõi thanh tr·∫°ng th√°i
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    status_text.write("B·∫Øt ƒë·∫ßu t·∫£i d·ªØ li·ªáu MNIST...")
    X, y = load_mnist()
    progress_bar.progress(100)
    status_text.write("D·ªØ li·ªáu MNIST ƒë√£ s·∫µn s√†ng! ‚úÖ")

    # Ch·ªçn s·ªë m·∫´u (gi·∫£m m·∫∑c ƒë·ªãnh ƒë·ªÉ tƒÉng t·ªëc)
    max_samples = st.slider("Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u (0 = to√†n b·ªô, t·ªëi ƒëa 70.000)", 0, 70000, 10000, step=1000)
    if max_samples == 0 or max_samples > len(X):
        st.warning(f"S·ªë m·∫´u {max_samples} v∆∞·ª£t qu√° {len(X)}. S·ª≠ d·ª•ng to√†n b·ªô {len(X)} m·∫´u.")
        max_samples = len(X)
    elif max_samples < len(X):
        indices = np.random.choice(len(X), max_samples, replace=False)
        X, y = X[indices], y[indices]

    # Ch·ªçn ph∆∞∆°ng ph√°p gi·∫£m chi·ªÅu
    method = st.selectbox("Ch·ªçn ph∆∞∆°ng ph√°p gi·∫£m chi·ªÅu", ["PCA", "t-SNE"])

    # Ch·ªçn s·ªë chi·ªÅu (ch·ªâ 2 ho·∫∑c 3)
    n_components = st.slider("Ch·ªçn s·ªë chi·ªÅu sau khi gi·∫£m (2 ho·∫∑c 3)", 2, 3, 2, step=1)

    # Hu·∫•n luy·ªán v√† tr·ª±c quan h√≥a
    if st.button("Gi·∫£m chi·ªÅu v√† tr·ª±c quan h√≥a", key="reduce_and_visualize"):
        with st.spinner("ƒêang th·ª±c hi·ªán gi·∫£m chi·ªÅu..."):
            X_reduced, model, duration = train_dimensionality_reduction(X, y, method, n_components)
            visualize_reduction(X_reduced, y, method, n_components)
        
        # Log k·∫øt qu·∫£
        log_results(method, n_components, duration, X, y, X_reduced, model)

    # Th√¥ng tin v·ªÅ ph∆∞∆°ng ph√°p
    st.subheader("üìö Th√¥ng tin v·ªÅ c√°c ph∆∞∆°ng ph√°p")
    if method == "PCA":
        st.write("""
            **PCA (Principal Component Analysis)**:
            - L√† k·ªπ thu·∫≠t tuy·∫øn t√≠nh gi·∫£m chi·ªÅu, gi·ªØ l·∫°i c√°c th√†nh ph·∫ßn ch√≠nh (principal components) gi·∫£i th√≠ch ph·∫ßn l·ªõn ph∆∞∆°ng sai trong d·ªØ li·ªáu.
            - ∆Øu ƒëi·ªÉm: Nhanh, d·ªÖ hi·ªÉu, hi·ªáu qu·∫£ v·ªõi d·ªØ li·ªáu tuy·∫øn t√≠nh.
            - Nh∆∞·ª£c ƒëi·ªÉm: Kh√¥ng ho·∫°t ƒë·ªông t·ªët v·ªõi d·ªØ li·ªáu phi tuy·∫øn.
        """)
    else:  # t-SNE
        st.write("""
            **t-SNE (t-Distributed Stochastic Neighbor Embedding)**:
            - L√† k·ªπ thu·∫≠t phi tuy·∫øn gi·∫£m chi·ªÅu, t·ªëi ∆∞u h√≥a ƒë·ªÉ b·∫£o to√†n c·∫•u tr√∫c c·ª•c b·ªô (local structure) c·ªßa d·ªØ li·ªáu.
            - ∆Øu ƒëi·ªÉm: T·ªët cho tr·ª±c quan h√≥a d·ªØ li·ªáu ph·ª©c t·∫°p, phi tuy·∫øn.
            - Nh∆∞·ª£c ƒëi·ªÉm: Ch·∫≠m, nh·∫°y v·ªõi tham s·ªë (perplexity, n_iter).
        """)

    # Th√™m n√∫t l√†m m·ªõi cache v·ªõi key duy nh·∫•t
    if st.button("üîÑ L√†m m·ªõi d·ªØ li·ªáu", key=f"refresh_data_{datetime.datetime.now().microsecond}"):
        st.cache_data.clear()
        st.rerun()

if __name__ == "__main__":
    dimensionality_reduction_app()