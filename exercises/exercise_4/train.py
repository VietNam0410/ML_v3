import streamlit as st
import numpy as np
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler
import plotly.graph_objects as go
import pandas as pd
import mlflow
import mlflow.sklearn
import os
import datetime
import time

# Thi·∫øt l·∫≠p MLflow v√† DagsHub
DAGSHUB_MLFLOW_URI = "https://dagshub.com/VietNam0410/ML_v3.mlflow"
mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
os.environ["MLFLOW_TRACKING_USERNAME"] = "VietNam0410"
os.environ["MLFLOW_TRACKING_PASSWORD"] = "c9db6bdcca1dfed76d2af2cdb15a9277e6732d6b"

# Cache scaler ƒë·ªÉ t√°i s·ª≠ d·ª•ng
@st.cache_resource
def get_scaler():
    return StandardScaler()

# H√†m train v·ªõi ti·∫øn tr√¨nh ƒë·ªìng b·ªô, ch·ªâ hi·ªÉn th·ªã thanh ti·∫øn tr√¨nh
@st.cache_data
def train_dimensionality_reduction(X, y, method, n_components):
    scaler = get_scaler()
    
    # Kh·ªüi t·∫°o thanh ti·∫øn tr√¨nh
    progress = st.progress(0)
    status_text = st.empty()

    # B∆∞·ªõc 1: Chu·∫©n h√≥a d·ªØ li·ªáu (20% ti·∫øn tr√¨nh)
    progress.progress(0.2)
    time.sleep(0.1)  # Gi·∫£ l·∫≠p th·ªùi gian x·ª≠ l√Ω
    X_scaled = scaler.fit_transform(X.reshape(X.shape[0], -1))
    
    start_time = datetime.datetime.now()
    if method == "PCA":
        # B∆∞·ªõc 2: Gi·∫£m chi·ªÅu v·ªõi PCA (80% ti·∫øn tr√¨nh)
        progress.progress(0.8)
        time.sleep(0.1)  # Gi·∫£ l·∫≠p th·ªùi gian x·ª≠ l√Ω
        model = PCA(n_components=n_components, svd_solver='randomized')
        X_reduced = model.fit_transform(X_scaled)
    elif method == "t-SNE":
        # B∆∞·ªõc 2: Gi·∫£m chi·ªÅu trung gian v·ªõi PCA (50% ti·∫øn tr√¨nh)
        progress.progress(0.5)
        time.sleep(0.1)  # Gi·∫£ l·∫≠p th·ªùi gian x·ª≠ l√Ω
        intermediate_dims = min(50, X_scaled.shape[1])
        pca = PCA(n_components=intermediate_dims, svd_solver='randomized')
        X_intermediate = pca.fit_transform(X_scaled)
        
        # B∆∞·ªõc 3: Gi·∫£m chi·ªÅu cu·ªëi c√πng v·ªõi t-SNE (100% ti·∫øn tr√¨nh)
        progress.progress(1.0)
        time.sleep(0.1)  # Gi·∫£ l·∫≠p th·ªùi gian x·ª≠ l√Ω
        perplexity = min(30, max(5, len(X) // 200))
        model = TSNE(n_components=n_components, perplexity=perplexity, max_iter=250, 
                     random_state=42, n_jobs=-1)
        X_reduced = model.fit_transform(X_intermediate)
    
    duration = (datetime.datetime.now() - start_time).total_seconds()
    status_text.text("Ho√†n t·∫•t gi·∫£m chi·ªÅu!")
    return X_reduced, model, duration

def visualize_reduction(X_reduced, y, method, n_components):
    if n_components == 2:
        df = pd.DataFrame({
            'x': X_reduced[:, 0],
            'y': X_reduced[:, 1],
            'label': y.astype(str)
        })
        fig = go.Figure()
        for label in sorted(df['label'].unique()):
            df_label = df[df['label'] == label]
            fig.add_trace(go.Scatter(
                x=df_label['x'], y=df_label['y'], mode='markers', marker=dict(size=5),
                name=f'Nh√£n {label}', hovertemplate='x: %{x:.2f}<br>y: %{y:.2f}<br>Nh√£n: %{customdata}<extra></extra>',
                customdata=df_label['label']
            ))
        fig.update_layout(title=f"Tr·ª±c quan h√≥a {method} (2D)", xaxis_title="Th√†nh ph·∫ßn 1", yaxis_title="Th√†nh ph·∫ßn 2", showlegend=True)
    else:
        df = pd.DataFrame({
            'x': X_reduced[:, 0], 'y': X_reduced[:, 1], 'z': X_reduced[:, 2], 'label': y.astype(str)
        })
        fig = go.Figure()
        for label in sorted(df['label'].unique()):
            df_label = df[df['label'] == label]
            fig.add_trace(go.Scatter3d(
                x=df_label['x'], y=df_label['y'], z=df_label['z'], mode='markers', marker=dict(size=3),
                name=f'Nh√£n {label}', hovertemplate='x: %{x:.2f}<br>y: %{y:.2f}<br>z: %{z:.2f}<br>Nh√£n: %{customdata}<extra></extra>',
                customdata=df_label['label']
            ))
        fig.update_layout(title=f"Tr·ª±c quan h√≥a {method} (3D)", scene=dict(xaxis_title="Th√†nh ph·∫ßn 1", yaxis_title="Th√†nh ph·∫ßn 2", zaxis_title="Th√†nh ph·∫ßn 3"), showlegend=True)
    
    st.plotly_chart(fig, use_container_width=True)

def log_results(method, n_components, duration, X, y, X_reduced, model):
    mlflow.set_experiment("MNIST_Dimensionality_Reduction")
    log_time = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    run_name = f"{method}_n={n_components}_{log_time}"
    
    with mlflow.start_run(run_name=run_name):
        mlflow.log_param("method", method)
        mlflow.log_param("n_components", n_components)
        mlflow.log_param("max_samples", len(X))
        mlflow.log_param("log_time", log_time)
        mlflow.log_metric("duration_seconds", duration)
        if method == "PCA":
            mlflow.log_metric("explained_variance_ratio", np.sum(model.explained_variance_ratio_))
        mlflow.sklearn.log_model(model, "model", input_example=X.reshape(X.shape[0], -1)[:1], signature=None)

def display_logs():
    client = mlflow.MlflowClient()
    experiment = client.get_experiment_by_name("MNIST_Dimensionality_Reduction")
    if not experiment:
        st.warning("Ch∆∞a c√≥ experiment 'MNIST_Dimensionality_Reduction'.")
        return
    
    runs = client.search_runs(experiment_ids=[experiment.experiment_id])
    if len(runs) == 0:
        st.warning("Kh√¥ng c√≥ log n√†o trong experiment.")
        return
    
    data = []
    for run in runs:
        run_name = run.data.tags.get("mlflow.runName", run.info.run_id)
        method = run.data.params.get("method", "N/A")
        n_components = run.data.params.get("n_components", "N/A")
        max_samples = run.data.params.get("max_samples", "N/A")
        log_time = run.data.params.get("log_time", "N/A")
        duration = run.data.metrics.get("duration_seconds", np.nan)
        explained_variance = run.data.metrics.get("explained_variance_ratio", np.nan)
        data.append({
            "Run ID": run.info.run_id,
            "T√™n Run": run_name,
            "Ph∆∞∆°ng ph√°p": method,
            "S·ªë chi·ªÅu": n_components,
            "S·ªë m·∫´u": max_samples,
            "Th·ªùi gian Log": log_time,
            "Th·ªùi gian ch·∫°y (gi√¢y)": duration,
            "Ph∆∞∆°ng sai gi·∫£i th√≠ch": explained_variance
        })
    
    df = pd.DataFrame(data, dtype='object')
    st.subheader("Log C√°c L·∫ßn Gi·∫£m Chi·ªÅu")
    st.dataframe(df, hide_index=True, width=1200)

def dimensionality_reduction_app(X, y):
    st.title("üåê Gi·∫£m Chi·ªÅu D·ªØ li·ªáu MNIST")
    total_samples = len(X)
    max_samples = st.slider("Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u", 1000, 70000, 5000, step=1000, key='max_samples_ex4')
    if max_samples < total_samples:
        indices = np.random.choice(total_samples, max_samples, replace=False)
        X, y = X[indices], y[indices]
    if max_samples > 30000:
        st.warning('S·ªë m·∫´u l·ªõn (>30,000) c√≥ th·ªÉ l√†m ch·∫≠m t-SNE. ƒê·ªÅ ngh·ªã gi·∫£m n·∫øu c·∫ßn.')

    method = st.selectbox("Ch·ªçn ph∆∞∆°ng ph√°p", ["PCA", "t-SNE"], key='method_ex4')
    n_components = st.slider("Ch·ªçn s·ªë chi·ªÅu", 2, 3, 2, key='n_components_ex4')

    if st.button("Gi·∫£m chi·ªÅu", key='reduce_button_ex4'):
        X_reduced, model, duration = train_dimensionality_reduction(X, y, method, n_components)
        visualize_reduction(X_reduced, y, method, n_components)
        log_results(method, n_components, duration, X, y, X_reduced, model)
        
        st.success(f"Ho√†n t·∫•t trong {duration:.2f} gi√¢y!")
        display_logs()  # Hi·ªÉn th·ªã log sau khi train