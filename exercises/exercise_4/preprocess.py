import streamlit as st
import numpy as np
import pandas as pd
import openml
from sklearn.model_selection import train_test_split
import mlflow
import os
import dagshub

# Thi·∫øt l·∫≠p th√¥ng tin DagsHub
DAGSHUB_USERNAME = "VietNam0410"
DAGSHUB_REPO = "vn0410"

try:
    with st.spinner("ƒêang k·∫øt n·ªëi v·ªõi DagsHub..."):
        dagshub.init(repo_owner=DAGSHUB_USERNAME, repo_name=DAGSHUB_REPO, mlflow=True)
        mlflow.set_tracking_uri(f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO}.mlflow")
        os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
        os.environ["MLFLOW_TRACKING_PASSWORD"] = os.getenv("MLFLOW_TRACKING_PASSWORD", "")
    st.success("ƒê√£ k·∫øt n·ªëi v·ªõi DagsHub th√†nh c√¥ng!")
except Exception as e:
    st.error(f"Kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi DagsHub: {str(e)}. S·ª≠ d·ª•ng MLflow c·ª•c b·ªô.")
    mlflow.set_tracking_uri(f"file://{os.path.abspath('mlruns')}")

# Cache d·ªØ li·ªáu MNIST
@st.cache_data
def load_mnist_data():
    with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu MNIST t·ª´ OpenML..."):
        dataset = openml.datasets.get_dataset(554)
        X, y, _, _ = dataset.get_data(target='class')
        X = X.values.reshape(-1, 28 * 28) / 255.0  # Chu·∫©n h√≥a v·ªÅ [0, 1]
        y = y.astype(np.int32)
    return X, y

def preprocess():
    st.header("Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu MNIST: PCA v√† t-SNE üßÆ")

    # Gi·ªõi thi·ªáu PCA
    st.subheader("1. PCA (Principal Component Analysis)")
    st.write("""
    PCA l√† m·ªôt ph∆∞∆°ng ph√°p gi·∫£m chi·ªÅu tuy·∫øn t√≠nh, bi·∫øn ƒë·ªïi d·ªØ li·ªáu th√†nh c√°c th√†nh ph·∫ßn ch√≠nh (principal components) 
    sao cho gi·ªØ ƒë∆∞·ª£c t·ªëi ƒëa ph∆∞∆°ng sai c·ªßa d·ªØ li·ªáu. C√°c th√¥ng s·ªë ƒëi·ªÅu ch·ªânh:
    - **S·ªë th√†nh ph·∫ßn (n_components):** S·ªë chi·ªÅu d·ªØ li·ªáu gi·∫£m xu·ªëng (m·∫∑c ƒë·ªãnh 2 ƒë·ªÉ tr·ª±c quan h√≥a).
    """)

    # Gi·ªõi thi·ªáu t-SNE
    st.subheader("2. t-SNE (t-Distributed Stochastic Neighbor Embedding)")
    st.write("""
    t-SNE l√† m·ªôt ph∆∞∆°ng ph√°p phi tuy·∫øn t√≠nh, t·∫≠p trung v√†o vi·ªác b·∫£o t·ªìn c·∫•u tr√∫c c·ª•c b·ªô c·ªßa d·ªØ li·ªáu trong kh√¥ng gian 
    chi·ªÅu th·∫•p. C√°c th√¥ng s·ªë ƒëi·ªÅu ch·ªânh:
    - **Perplexity:** ƒê·ªô c√¢n b·∫±ng gi·ªØa c·∫•u tr√∫c c·ª•c b·ªô v√† to√†n c·ª•c (th∆∞·ªùng t·ª´ 5-50).
    - **S·ªë l·∫ßn l·∫∑p (n_iter):** S·ªë l·∫ßn t·ªëi ∆∞u h√≥a (th∆∞·ªùng t·ª´ 250-1000).
    """)

    # Thi·∫øt l·∫≠p experiment
    experiment_name = st.text_input("Nh·∫≠p t√™n Experiment", value="MNIST_DimReduction")
    if experiment_name:
        with st.spinner("ƒêang thi·∫øt l·∫≠p Experiment tr√™n DagsHub..."):
            mlflow.set_experiment(experiment_name)

    # T·∫£i d·ªØ li·ªáu MNIST
    if 'X_full' not in st.session_state or 'y_full' not in st.session_state:
        st.session_state['X_full'], st.session_state['y_full'] = load_mnist_data()
        st.success(f"ƒê√£ t·∫£i d·ªØ li·ªáu MNIST: {st.session_state['X_full'].shape[0]} m·∫´u, {st.session_state['X_full'].shape[1]} ƒë·∫∑c tr∆∞ng")

    X_full = st.session_state['X_full']
    y_full = st.session_state['y_full']

    # Ch·ªçn s·ªë m·∫´u
    max_samples = st.slider("Ch·ªçn s·ªë m·∫´u ƒë·ªÉ x·ª≠ l√Ω (√≠t h∆°n ƒë·ªÉ nhanh h∆°n)", 100, X_full.shape[0], 1000)
    if max_samples < X_full.shape[0]:
        indices = np.random.choice(X_full.shape[0], max_samples, replace=False)
        X_subset = X_full[indices]
        y_subset = y_full[indices]
    else:
        X_subset = X_full
        y_subset = y_full

    # Chia t·∫≠p d·ªØ li·ªáu: test tr∆∞·ªõc, sau ƒë√≥ train/validation
    st.subheader("Chia t·∫≠p d·ªØ li·ªáu")
    test_size = st.slider("T·ª∑ l·ªá t·∫≠p ki·ªÉm tra (%)", 10, 50, 20) / 100
    valid_size = st.slider("T·ª∑ l·ªá t·∫≠p validation (trong ph·∫ßn c√≤n l·∫°i) (%)", 10, 50, 20) / 100

    if st.button("Chia d·ªØ li·ªáu"):
        with st.spinner("ƒêang chia d·ªØ li·ªáu..."):
            # Chia t·∫≠p test tr∆∞·ªõc
            X_temp, X_test, y_temp, y_test = train_test_split(X_subset, y_subset, test_size=test_size, random_state=42)
            # Chia t·∫≠p train v√† validation t·ª´ ph·∫ßn c√≤n l·∫°i
            valid_size_adjusted = valid_size / (1 - test_size)  # ƒêi·ªÅu ch·ªânh t·ª∑ l·ªá validation
            X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=valid_size_adjusted, random_state=42)

            # L∆∞u v√†o session_state
            st.session_state['mnist_data'] = {
                'X_train': X_train,
                'y_train': y_train,
                'X_valid': X_valid,
                'y_valid': y_valid,
                'X_test': X_test,
                'y_test': y_test
            }

            st.success(f"ƒê√£ chia d·ªØ li·ªáu: Train {len(X_train)}, Validation {len(X_valid)}, Test {len(X_test)}")

            # Logging v·ªõi MLflow
            with mlflow.start_run(run_name=f"Data_Split_{max_samples}"):
                mlflow.log_param("max_samples", max_samples)
                mlflow.log_param("test_size", test_size)
                mlflow.log_param("valid_size", valid_size)
                mlflow.log_metric("train_samples", len(X_train))
                mlflow.log_metric("valid_samples", len(X_valid))
                mlflow.log_metric("test_samples", len(X_test))

if __name__ == "__main__":
    preprocess()