import streamlit as st
import numpy as np
import pandas as pd
import openml
from sklearn.model_selection import train_test_split
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns
import mlflow
import os
import dagshub

# Ph·∫ßn kh·ªüi t·∫°o k·∫øt n·ªëi v·ªõi DagsHub ƒë∆∞·ª£c comment ƒë·ªÉ kh√¥ng truy c·∫≠p ngay l·∫≠p t·ª©c
# with st.spinner("ƒêang k·∫øt n·ªëi v·ªõi DagsHub..."):
#     dagshub.init(repo_owner='VietNam0410', repo_name='vn0410', mlflow=True)
#     mlflow.set_tracking_uri(f"https://dagshub.com/VietNam0410/vn0410.mlflow")
# st.success("ƒê√£ k·∫øt n·ªëi v·ªõi DagsHub th√†nh c√¥ng!")

# Cache d·ªØ li·ªáu MNIST
@st.cache_data
def load_mnist_data():
    with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu MNIST t·ª´ OpenML..."):
        dataset = openml.datasets.get_dataset(554)
        X, y, _, _ = dataset.get_data(target='class')
        X = X.values.reshape(-1, 28 * 28) / 255.0  # Chu·∫©n h√≥a v·ªÅ [0, 1]
        y = y.astype(np.int32)
    return X, y

def plot_reduction(X_reduced, y, method, params):
    """V·∫Ω bi·ªÉu ƒë·ªì scatter v√† l∆∞u c·ª•c b·ªô."""
    fig, ax = plt.subplots(figsize=(10, 6))
    sns.scatterplot(x=X_reduced[:, 0], y=X_reduced[:, 1], hue=y, palette="tab10", ax=ax, s=10)
    ax.set_title(f"{method} Visualization of MNIST")
    ax.set_xlabel(f"{method} Component 1")
    ax.set_ylabel(f"{method} Component 2")
    st.pyplot(fig)

    # L∆∞u plot v√†o file c·ª•c b·ªô
    plot_file = f"{method.lower()}_plot.png"
    fig.savefig(plot_file)
    st.info(f"Bi·ªÉu ƒë·ªì {method} ƒë√£ ƒë∆∞·ª£c l∆∞u c·ª•c b·ªô t·∫°i: {plot_file}")

def preprocess():
    st.header("Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu MNIST: PCA v√† t-SNE üßÆ")

    # Gi·ªõi thi·ªáu PCA
    st.subheader("1. PCA (Principal Component Analysis)")
    st.write("""
    PCA l√† m·ªôt ph∆∞∆°ng ph√°p gi·∫£m chi·ªÅu tuy·∫øn t√≠nh, bi·∫øn ƒë·ªïi d·ªØ li·ªáu th√†nh c√°c th√†nh ph·∫ßn ch√≠nh (principal components) 
    sao cho gi·ªØ ƒë∆∞·ª£c t·ªëi ƒëa ph∆∞∆°ng sai c·ªßa d·ªØ li·ªáu. C√°c th√¥ng s·ªë ƒëi·ªÅu ch·ªânh:
    - **S·ªë th√†nh ph·∫ßn (n_components):** S·ªë chi·ªÅu d·ªØ li·ªáu gi·∫£m xu·ªëng (m·∫∑c ƒë·ªãnh 2 ƒë·ªÉ tr·ª±c quan h√≥a).
    """)

    # Gi·ªõi thi·ªáu t-SNE
    st.subheader("2. t-SNE (t-Distributed Stochastic Neighbor Embedding)")
    st.write("""
    t-SNE l√† m·ªôt ph∆∞∆°ng ph√°p phi tuy·∫øn t√≠nh, t·∫≠p trung v√†o vi·ªác b·∫£o t·ªìn c·∫•u tr√∫c c·ª•c b·ªô c·ªßa d·ªØ li·ªáu trong kh√¥ng gian 
    chi·ªÅu th·∫•p. C√°c th√¥ng s·ªë ƒëi·ªÅu ch·ªânh:
    - **Perplexity:** ƒê·ªô c√¢n b·∫±ng gi·ªØa c·∫•u tr√∫c c·ª•c b·ªô v√† to√†n c·ª•c (th∆∞·ªùng t·ª´ 5-50).
    - **S·ªë l·∫ßn l·∫∑p (n_iter):** S·ªë l·∫ßn t·ªëi ∆∞u h√≥a (th∆∞·ªùng t·ª´ 250-1000).
    """)

    # Thi·∫øt l·∫≠p experiment (kh√¥ng c·∫ßn k·∫øt n·ªëi DagsHub)
    experiment_name = st.text_input("Nh·∫≠p t√™n Experiment", value="MNIST_DimReduction")
    # if experiment_name:
    #     with st.spinner("ƒêang thi·∫øt l·∫≠p Experiment tr√™n DagsHub..."):
    #         mlflow.set_experiment(experiment_name)

    # T·∫£i d·ªØ li·ªáu MNIST
    if 'X_full' not in st.session_state or 'y_full' not in st.session_state:
        st.session_state['X_full'], st.session_state['y_full'] = load_mnist_data()
        st.success(f"ƒê√£ t·∫£i d·ªØ li·ªáu MNIST: {st.session_state['X_full'].shape[0]} m·∫´u, {st.session_state['X_full'].shape[1]} ƒë·∫∑c tr∆∞ng")

    X_full = st.session_state['X_full']
    y_full = st.session_state['y_full']

    # Ch·ªçn s·ªë m·∫´u
    max_samples = st.slider("Ch·ªçn s·ªë m·∫´u ƒë·ªÉ x·ª≠ l√Ω (√≠t h∆°n ƒë·ªÉ nhanh h∆°n)", 100, X_full.shape[0], 1000)
    if max_samples < X_full.shape[0]:
        indices = np.random.choice(X_full.shape[0], max_samples, replace=False)
        X_subset = X_full[indices]
        y_subset = y_full[indices]
    else:
        X_subset = X_full
        y_subset = y_full

    # Chia t·∫≠p d·ªØ li·ªáu: test tr∆∞·ªõc, sau ƒë√≥ train/validation
    st.subheader("Chia t·∫≠p d·ªØ li·ªáu")
    test_size = st.slider("T·ª∑ l·ªá t·∫≠p ki·ªÉm tra (%)", 10, 50, 20) / 100
    remaining_size = 1 - test_size
    train_size_relative = st.slider("T·ª∑ l·ªá t·∫≠p hu·∫•n luy·ªán (trong ph·∫ßn c√≤n l·∫°i) (%)", 10, 90, 70) / 100

    # T√≠nh to√°n t·ª∑ l·ªá th·ª±c t·∫ø
    train_size = remaining_size * train_size_relative
    valid_size = remaining_size * (1 - train_size_relative)

    # Hi·ªÉn th·ªã t·ª∑ l·ªá th·ª±c t·∫ø
    st.write(f"T·ª∑ l·ªá th·ª±c t·∫ø: Hu·∫•n luy·ªán {train_size*100:.1f}%, Validation {valid_size*100:.1f}%, Ki·ªÉm tra {test_size*100:.1f}%")
    st.write(f"Ki·ªÉm tra t·ªïng t·ª∑ l·ªá: {train_size*100 + valid_size*100 + test_size*100:.1f}% (ph·∫£i lu√¥n b·∫±ng 100%)")

    if st.button("Chia d·ªØ li·ªáu v√† gi·∫£m chi·ªÅu"):
        with st.spinner("ƒêang chia d·ªØ li·ªáu..."):
            # Chia t·∫≠p test tr∆∞·ªõc
            X_temp, X_test, y_temp, y_test = train_test_split(X_subset, y_subset, test_size=test_size, random_state=42)
            # Chia t·∫≠p train v√† validation t·ª´ ph·∫ßn c√≤n l·∫°i
            X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, train_size=train_size_relative, random_state=42)

            # L∆∞u v√†o session_state
            st.session_state['mnist_data'] = {
                'X_train': X_train,
                'y_train': y_train,
                'X_valid': X_valid,
                'y_valid': y_valid,
                'X_test': X_test,
                'y_test': y_test
            }

            st.success(f"ƒê√£ chia d·ªØ li·ªáu: Train {len(X_train)}, Validation {len(X_valid)}, Test {len(X_test)}")

            # Chu·∫©n h√≥a d·ªØ li·ªáu
            with st.spinner("ƒêang chu·∫©n h√≥a d·ªØ li·ªáu..."):
                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_valid_scaled = scaler.transform(X_valid)
                X_test_scaled = scaler.transform(X_test)

            # Gi·∫£m chi·ªÅu b·∫±ng PCA
            with st.spinner("ƒêang gi·∫£m chi·ªÅu b·∫±ng PCA..."):
                pca = PCA(n_components=2)
                X_train_pca = pca.fit_transform(X_train_scaled)
                X_valid_pca = pca.transform(X_valid_scaled)
                X_test_pca = pca.transform(X_test_scaled)
                explained_variance_ratio = pca.explained_variance_ratio_.sum()

                st.success(f"PCA ho√†n t·∫•t! T·ª∑ l·ªá ph∆∞∆°ng sai gi·∫£i th√≠ch: {explained_variance_ratio:.4f}")
                plot_reduction(X_train_pca, y_train, "PCA", {"n_components": 2})

                st.session_state['pca_model'] = pca
                st.session_state['X_train_pca'] = X_train_pca
                st.session_state['X_valid_pca'] = X_valid_pca
                st.session_state['X_test_pca'] = X_test_pca

            # Gi·∫£m chi·ªÅu b·∫±ng t-SNE
            with st.spinner("ƒêang gi·∫£m chi·ªÅu b·∫±ng t-SNE (c√≥ th·ªÉ l√¢u v·ªõi d·ªØ li·ªáu l·ªõn)..."):
                tsne = TSNE(n_components=2, perplexity=30, n_iter=500, random_state=42)
                X_train_tsne = tsne.fit_transform(X_train_scaled)
                X_valid_tsne = tsne.fit_transform(X_valid_scaled)  # t-SNE kh√¥ng c√≥ transform, c·∫ßn t√≠nh l·∫°i
                X_test_tsne = tsne.fit_transform(X_test_scaled)

                st.success("t-SNE ho√†n t·∫•t!")
                plot_reduction(X_train_tsne, y_train, "t-SNE", {"perplexity": 30, "n_iter": 500})

                st.session_state['tsne_model'] = tsne
                st.session_state['X_train_tsne'] = X_train_tsne
                st.session_state['X_valid_tsne'] = X_valid_tsne
                st.session_state['X_test_tsne'] = X_test_tsne

            # Comment ph·∫ßn logging v·ªõi MLflow
            # with mlflow.start_run(run_name=f"Data_Split_{max_samples}") as run:
            #     mlflow.log_param("max_samples", max_samples)
            #     mlflow.log_param("test_size", test_size)
            #     mlflow.log_param("valid_size", valid_size)
            #     mlflow.log_metric("train_samples", len(X_train))
            #     mlflow.log_metric("valid_samples", len(X_valid))
            #     mlflow.log_metric("test_samples", len(X_test))

            # with mlflow.start_run(run_name=f"PCA_{max_samples}") as run:
            #     mlflow.log_param("method", "PCA")
            #     mlflow.log_param("n_components", 2)
            #     mlflow.log_param("n_samples", X_train_scaled.shape[0])
            #     mlflow.log_metric("explained_variance_ratio", explained_variance_ratio)
            #     mlflow.sklearn.log_model(pca, "pca_model")
            #     plot_reduction(X_train_pca, y_train, "PCA", {"n_components": 2})

            # with mlflow.start_run(run_name=f"tSNE_{max_samples}") as run:
            #     mlflow.log_param("method", "t-SNE")
            #     mlflow.log_param("perplexity", 30)
            #     mlflow.log_param("n_iter", 500)
            #     mlflow.log_param("n_samples", X_train_scaled.shape[0])
            #     mlflow.sklearn.log_model(tsne, "tsne_model")
            #     plot_reduction(X_train_tsne, y_train, "t-SNE", {"perplexity": 30, "n_iter": 500})

if __name__ == "__main__":
    preprocess()