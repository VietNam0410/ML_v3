import streamlit as st
import mlflow
import os  # ƒê·∫£m b·∫£o import os ƒë·ªÉ tr√°nh l·ªói

def show_mnist_demo():
    st.title("üìä Xem Logs Hu·∫•n Luy·ªán MNIST")
    st.markdown("Danh s√°ch c√°c l·∫ßn hu·∫•n luy·ªán (runs) ƒë∆∞·ª£c l∆∞u trong MLflow.")

    # Thi·∫øt l·∫≠p MLflow
    mlflow.set_tracking_uri("https://dagshub.com/VietNam0410/ML_v3.mlflow")
    os.environ["MLFLOW_TRACKING_USERNAME"] = "VietNam0410"
    os.environ["MLFLOW_TRACKING_PASSWORD"] = "c9db6bdcca1dfed76d2af2cdb15a9277e6732d6b"

    # L·∫•y danh s√°ch c√°c run t·ª´ MLflow
    experiment = mlflow.get_experiment_by_name("MNIST_Neural_Network")
    if experiment is None:
        st.error("Kh√¥ng t√¨m th·∫•y experiment 'MNIST_Neural_Network' trong MLflow.")
        return
    runs = mlflow.search_runs(experiment_ids=[experiment.experiment_id])

    # Ki·ªÉm tra n·∫øu kh√¥ng c√≥ run n√†o
    if runs.empty:
        st.warning("Kh√¥ng c√≥ run n√†o ƒë∆∞·ª£c t√¨m th·∫•y. Vui l√≤ng hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc.")
        return

    # Hi·ªÉn th·ªã danh s√°ch c√°c run
    st.subheader("Danh S√°ch C√°c Run ƒê√£ L∆∞u")
    expected_columns = ['params.n_hidden_layers', 'params.neurons_per_layer', 'params.epochs', 
                        'params.batch_size', 'params.learning_rate', 'params.activation', 
                        'params.samples', 'metrics.train_accuracy', 'metrics.val_accuracy',
                        'metrics.train_loss', 'metrics.val_loss']
    for col in expected_columns:
        if col not in runs.columns:
            runs[col] = None
    st.dataframe(runs[['run_id', 'params.log_time'] + expected_columns])

    # Ch·ªçn m·ªôt run ƒë·ªÉ xem chi ti·∫øt
    run_options = runs['run_id'].tolist()
    selected_run = st.selectbox("Ch·ªçn m·ªôt run ƒë·ªÉ xem chi ti·∫øt:", run_options, index=0)
    run_info = mlflow.get_run(selected_run)

    # Hi·ªÉn th·ªã th√¥ng tin chi ti·∫øt v·ªÅ run
    st.subheader("Th√¥ng Tin Run ƒê∆∞·ª£c Ch·ªçn")
    st.write(f"**Run ID**: {selected_run}")
    if run_info.data.metrics:
        st.write(f"**ƒê·ªô ch√≠nh x√°c (Train)**: {run_info.data.metrics.get('train_accuracy', 'N/A') if isinstance(run_info.data.metrics.get('train_accuracy', 'N/A'), (int, float)) else run_info.data.metrics.get('train_accuracy', 'N/A'):.4f}")
        st.write(f"**ƒê·ªô ch√≠nh x√°c (Validation)**: {run_info.data.metrics.get('val_accuracy', 'N/A') if isinstance(run_info.data.metrics.get('val_accuracy', 'N/A'), (int, float)) else run_info.data.metrics.get('val_accuracy', 'N/A'):.4f}")
        st.write(f"**M·∫•t m√°t (Train)**: {run_info.data.metrics.get('train_loss', 'N/A') if isinstance(run_info.data.metrics.get('train_loss', 'N/A'), (int, float)) else run_info.data.metrics.get('train_loss', 'N/A'):.4f}")
        st.write(f"**M·∫•t m√°t (Validation)**: {run_info.data.metrics.get('val_loss', 'N/A') if isinstance(run_info.data.metrics.get('val_loss', 'N/A'), (int, float)) else run_info.data.metrics.get('val_loss', 'N/A'):.4f}")
    else:
        st.warning("Kh√¥ng c√≥ metrics n√†o ƒë∆∞·ª£c ghi l·∫°i cho run n√†y.")

    if run_info.data.params:
        st.write("**Tham s·ªë Hu·∫•n Luy·ªán**:")
        st.write(f"- S·ªë l·ªõp ·∫©n: {run_info.data.params.get('n_hidden_layers', 'N/A')}")
        st.write(f"- S·ªë n∆°-ron m·ªói l·ªõp: {run_info.data.params.get('neurons_per_layer', 'N/A')}")
        st.write(f"- S·ªë v√≤ng l·∫∑p (epochs): {run_info.data.params.get('epochs', 'N/A')}")
        st.write(f"- K√≠ch th∆∞·ªõc batch: {run_info.data.params.get('batch_size', 'N/A')}")
        st.write(f"- T·ªëc ƒë·ªô h·ªçc (Œ∑): {run_info.data.params.get('learning_rate', 'N/A')}")
        st.write(f"- H√†m k√≠ch ho·∫°t: {run_info.data.params.get('activation', 'N/A')}")
        st.write(f"- S·ªë m·∫´u hu·∫•n luy·ªán: {run_info.data.params.get('samples', 'N/A')}")
        st.write(f"- Th·ªùi gian hu·∫•n luy·ªán: {run_info.data.params.get('log_time', 'N/A')}")
    else:
        st.warning("Kh√¥ng c√≥ tham s·ªë n√†o ƒë∆∞·ª£c ghi l·∫°i cho run n√†y.")