import streamlit as st
import pandas as pd
import mlflow
import mlflow.sklearn
from sklearn.model_selection import train_test_split, KFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import Pipeline
from common.utils import load_data
import os
import dagshub

# H√†m kh·ªüi t·∫°o MLflow
def mlflow_input():
    DAGSHUB_MLFLOW_URI = "https://dagshub.com/VietNam0410/vn0410.mlflow"
    mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
    st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
    os.environ["MLFLOW_TRACKING_USERNAME"] = "VietNam0410"
    os.environ["MLFLOW_TRACKING_PASSWORD"] = "22fd02345f8ff45482a20960058627630acaf190"  # Thay b·∫±ng token c√° nh√¢n c·ªßa b·∫°n
    DAGSHUB_REPO = "vn0410"
    return DAGSHUB_REPO

def train_model():
    st.header("Train Titanic Survival Model üßë‚ÄçüöÄ")

    # ƒê√≥ng b·∫•t k·ª≥ run n√†o ƒëang ho·∫°t ƒë·ªông ƒë·ªÉ tr√°nh xung ƒë·ªôt khi b·∫Øt ƒë·∫ßu
    if mlflow.active_run():
        mlflow.end_run()
        st.info("ƒê√£ ƒë√≥ng run MLflow ƒëang ho·∫°t ƒë·ªông tr∆∞·ªõc ƒë√≥.")

    # G·ªçi h√†m mlflow_input ƒë·ªÉ thi·∫øt l·∫≠p MLflow
    DAGSHUB_REPO = mlflow_input()

    # Cho ng∆∞·ªùi d√πng ƒë·∫∑t t√™n Experiment
    experiment_name = st.text_input("Enter Experiment Name for Training", value="Titanic_Training")
    with st.spinner("ƒêang thi·∫øt l·∫≠p Experiment tr√™n DagsHub..."):
        try:
            client = mlflow.tracking.MlflowClient()
            experiment = client.get_experiment_by_name(experiment_name)
            if experiment and experiment.lifecycle_stage == "deleted":
                st.warning(f"Experiment '{experiment_name}' ƒë√£ b·ªã x√≥a tr∆∞·ªõc ƒë√≥. Vui l√≤ng ch·ªçn t√™n kh√°c ho·∫∑c kh√¥i ph·ª•c experiment qua DagsHub UI.")
                new_experiment_name = st.text_input("Nh·∫≠p t√™n Experiment m·ªõi", value=f"{experiment_name}_Restored_{datetime.datetime.now().strftime('%Y%m%d')}")
                if new_experiment_name:
                    mlflow.set_experiment(new_experiment_name)
                    experiment_name = new_experiment_name
                else:
                    st.error("Vui l√≤ng nh·∫≠p t√™n experiment m·ªõi ƒë·ªÉ ti·∫øp t·ª•c.")
                    return
            else:
                mlflow.set_experiment(experiment_name)
        except Exception as e:
            st.error(f"L·ªói khi thi·∫øt l·∫≠p experiment: {str(e)}")
            return     

    processed_file = "exercises/exercise_1/data/processed/titanic_processed.csv"
    try:
        with st.spinner("ƒêang t·∫£i d·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω..."):
            data = load_data(processed_file)
        st.subheader("D·ªØ li·ªáu ƒë√£ ti·ªÅn x·ª≠ l√Ω (Sau khi x·ª≠ l√Ω) üìù")
        st.write("ƒê√¢y l√† d·ªØ li·ªáu sau c√°c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω trong 'Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu Titanic':")
        st.write(data.head())
        
        # Hi·ªÉn th·ªã c√°c c·ªôt trong d·ªØ li·ªáu ƒë·ªÉ ki·ªÉm tra
        st.write("C√°c c·ªôt hi·ªán c√≥ trong d·ªØ li·ªáu:", data.columns.tolist())
    except FileNotFoundError:
        st.error("D·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω kh√¥ng t√¨m th·∫•y. Vui l√≤ng ho√†n t·∫•t ti·ªÅn x·ª≠ l√Ω trong 'Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu Titanic' tr∆∞·ªõc.")
        return

    # Ki·ªÉm tra s·ª± t·ªìn t·∫°i c·ªßa c·ªôt 'Survived'
    if 'Survived' not in data.columns:
        st.error("C·ªôt 'Survived' kh√¥ng t·ªìn t·∫°i trong d·ªØ li·ªáu. ƒê√¢y l√† c·ªôt target c·∫ßn thi·∫øt ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh. Vui l√≤ng ki·ªÉm tra file CSV ƒë·∫ßu v√†o ho·∫∑c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω ƒë·ªÉ ƒë·∫£m b·∫£o c·ªôt n√†y kh√¥ng b·ªã x√≥a.")
        return

    X = data.drop(columns=['Survived'])
    y = data['Survived']

    st.subheader("Chia d·ªØ li·ªáu üîÄ")
    test_size = st.slider("Ch·ªçn k√≠ch th∆∞·ªõc t·∫≠p ki·ªÉm tra (%)", min_value=10, max_value=50, value=20, step=5, key="test_size_slider") / 100
    remaining_size = 1 - test_size
    valid_size_relative = st.slider(
        "Ch·ªçn k√≠ch th∆∞·ªõc t·∫≠p validation (% d·ªØ li·ªáu c√≤n l·∫°i sau khi chia test)",
        min_value=0, max_value=50, value=20, step=5, key="valid_size_slider"
    ) / 100
    valid_size = remaining_size * valid_size_relative
    train_size = remaining_size - valid_size

    if st.button("Chia d·ªØ li·ªáu"):
        with st.spinner("ƒêang chia d·ªØ li·ªáu..."):
            X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
            X_train_initial, X_valid, y_train_initial, y_valid = train_test_split(
                X_temp, y_temp, test_size=valid_size / (1 - test_size), random_state=42
            )

            st.write(f"T·∫≠p hu·∫•n luy·ªán ban ƒë·∫ßu: {len(X_train_initial)} m·∫´u ({train_size*100:.1f}%)")
            st.write(f"T·∫≠p validation: {len(X_valid)} m·∫´u ({valid_size*100:.1f}%)")
            st.write(f"T·∫≠p ki·ªÉm tra: {len(X_test)} m·∫´u ({test_size*100:.1f}%)")
            st.write("D·ªØ li·ªáu hu·∫•n luy·ªán (X_train):", X_train_initial.head())
            st.write("D·ªØ li·ªáu validation (X_valid):", X_valid.head())
            st.write("D·ªØ li·ªáu ki·ªÉm tra (X_test):", X_test.head())

            # Logging chia d·ªØ li·ªáu v√†o MLflow tr√™n DagsHub
            with mlflow.start_run(run_name="Data_Split") as run:
                mlflow.log_param("test_size", test_size)
                mlflow.log_param("valid_size", valid_size)
                mlflow.log_param("train_size", train_size)
                run_id = run.info.run_id
                mlflow_uri = st.session_state['mlflow_url']
                st.success("D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia v√† log v√†o MLflow ‚úÖ.")
                st.markdown(f"Xem chi ti·∫øt t·∫°i: [DagsHub MLflow Tracking]({mlflow_uri})")

            st.session_state['X_train_initial'] = X_train_initial
            st.session_state['X_valid'] = X_valid
            st.session_state['X_test'] = X_test
            st.session_state['y_train_initial'] = y_train_initial
            st.session_state['y_valid'] = y_valid
            st.session_state['y_test'] = y_test

    st.subheader("Cross Validation (T√πy ch·ªçn) üîÑ")
    use_cv = st.checkbox("S·ª≠ d·ª•ng Cross Validation")
    if use_cv:
        if 'X_train_initial' not in st.session_state or 'X_test' not in st.session_state:
            st.warning("Vui l√≤ng chia d·ªØ li·ªáu tr∆∞·ªõc khi th·ª±c hi·ªán Cross Validation.")
            return

        k_folds = st.slider("Ch·ªçn s·ªë l∆∞·ª£ng folds (k)", min_value=2, max_value=10, value=5, key="k_folds_slider")

        if 'valid_sizes' not in st.session_state:
            st.session_state['valid_sizes'] = [20] * k_folds

        st.write("Ph√¢n b·ªï t·ª∑ l·ªá t·∫≠p valid cho t·ª´ng fold (t·ªïng = 100%)")
        valid_sizes = []
        total_valid = 0
        for i in range(k_folds):
            fold_num = i + 1
            valid_size = st.slider(
                f"Ch·ªçn k√≠ch th∆∞·ªõc t·∫≠p valid cho Fold {fold_num} (%)",
                min_value=0, max_value=100 - total_valid, value=st.session_state['valid_sizes'][i],
                key=f"valid_size_fold_{fold_num}"
            )
            valid_sizes.append(valid_size)
            total_valid += valid_size
            if total_valid > 100:
                st.error("T·ªïng t·ª∑ l·ªá valid v∆∞·ª£t qu√° 100%. Vui l√≤ng ƒëi·ªÅu ch·ªânh l·∫°i.")
                return

        if st.button("T·∫°o v√† t√πy ch·ªânh Cross Validation Folds"):
            if total_valid != 100:
                st.error("T·ªïng t·ª∑ l·ªá valid ph·∫£i b·∫±ng 100%. Vui l√≤ng ƒëi·ªÅu ch·ªânh l·∫°i.")
                return

            X_train_initial = st.session_state['X_train_initial']
            y_train_initial = st.session_state['y_train_initial']
            X_test = st.session_state['X_test']
            y_test = st.session_state['y_test']

            with st.spinner("ƒêang t·∫°o v√† t√πy ch·ªânh Cross Validation Folds..."):
                kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)
                fold_configs = {}
                fold_indices = list(kf.split(X_train_initial))

                for fold, (train_idx, valid_idx) in enumerate(fold_indices):
                    fold_num = fold + 1
                    X_remaining = X_train_initial.iloc[train_idx.tolist() + valid_idx.tolist()]
                    y_remaining = y_train_initial.iloc[train_idx.tolist() + valid_idx.tolist()]

                    valid_size_fold_relative = valid_sizes[fold] / 100

                    X_train_fold, X_valid_fold, y_train_fold, y_valid_fold = train_test_split(
                        X_remaining, y_remaining, test_size=valid_size_fold_relative, random_state=42
                    )

                    fold_configs[fold_num] = {
                        "X_train": X_train_fold,
                        "y_train": y_train_fold,
                        "X_valid": X_valid_fold,
                        "y_valid": y_valid_fold,
                        "train_size": len(X_train_fold),
                        "valid_size": len(X_valid_fold),
                        "valid_size_relative": valid_size_fold_relative
                    }

                st.session_state['fold_configs'] = fold_configs
                st.session_state['valid_sizes'] = valid_sizes

                st.subheader("T·ªïng quan c√°c Fold ƒë√£ t√πy ch·ªânh")
                fold_summary = []
                for fold_num, config in fold_configs.items():
                    fold_summary.append({
                        "Fold": fold_num,
                        "Train Size": config["train_size"],
                        "Valid Size": config["valid_size"],
                        "Test Size": len(X_test)
                    })
                fold_summary_df = pd.DataFrame(fold_summary)
                st.write(fold_summary_df)

                # Logging cross-validation v√†o MLflow tr√™n DagsHub
                with mlflow.start_run(run_name=f"CV_{k_folds}_Folds_Summary") as run:
                    mlflow.log_param("k_folds", k_folds)
                    for i, size in enumerate(valid_sizes):
                        mlflow.log_param(f"fold_{i+1}_valid_size", size)
                    for _, row in fold_summary_df.iterrows():
                        mlflow.log_metric(f"fold_{row['Fold']}_train_size", row["Train Size"])
                        mlflow.log_metric(f"fold_{row['Fold']}_valid_size", row["Valid Size"])
                        mlflow.log_metric(f"fold_{row['Fold']}_test_size", row["Test Size"])
                    run_id = run.info.run_id
                    mlflow_uri = st.session_state['mlflow_url']
                    st.success(f"T·∫°o v√† t√πy ch·ªânh {k_folds}-fold cross validation, log v√†o MLflow ‚úÖ.")
                    st.markdown(f"Xem chi ti·∫øt t·∫°i: [DagsHub MLflow Tracking]({mlflow_uri})")

    st.subheader("Hu·∫•n luy·ªán m√¥ h√¨nh üéØ")
    if 'X_train_initial' not in st.session_state:
        st.warning("Vui l√≤ng chia d·ªØ li·ªáu tr∆∞·ªõc khi hu·∫•n luy·ªán.")
        return

    # Gi·ªõi thi·ªáu c√°c tham s·ªë c·ªßa m√¥ h√¨nh
    st.write("### Gi·ªõi thi·ªáu c√°c tham s·ªë c·ªßa m√¥ h√¨nh")
    st.write("#### Random Forest")
    st.write("- **n_estimators**: S·ªë l∆∞·ª£ng c√¢y trong r·ª´ng (tƒÉng l√™n c·∫£i thi·ªán hi·ªáu su·∫•t nh∆∞ng t·ªën t√†i nguy√™n).")
    st.write("- **max_depth**: ƒê·ªô s√¢u t·ªëi ƒëa c·ªßa m·ªói c√¢y (gi·ªõi h·∫°n ƒë·ªÉ tr√°nh overfitting).")
    st.write("#### Logistic Regression")
    st.write("- **C**: C∆∞·ªùng ƒë·ªô ƒëi·ªÅu ch·ªânh (gi√° tr·ªã nh·ªè tƒÉng regularization, gi·∫£m overfitting).")
    st.write("- **max_iter**: S·ªë v√≤ng l·∫∑p t·ªëi ƒëa ƒë·ªÉ h·ªôi t·ª• (tƒÉng n·∫øu m√¥ h√¨nh kh√¥ng h·ªôi t·ª•).")
    st.write("#### Polynomial Regression")
    st.write("- **degree**: B·∫≠c c·ªßa ƒëa th·ª©c (tƒÉng ƒë·ªÉ m√¥ h√¨nh ph·ª©c t·∫°p h∆°n).")
    st.write("- **C**: C∆∞·ªùng ƒë·ªô ƒëi·ªÅu ch·ªânh c·ªßa Logistic Regression trong pipeline.")

    model_choice = st.selectbox(
        "Ch·ªçn m√¥ h√¨nh",
        ["Random Forest", "Logistic Regression", "Polynomial Regression"]
    )

    if model_choice == "Random Forest":
        n_estimators = st.slider("S·ªë l∆∞·ª£ng c√¢y (n_estimators)", 10, 200, 100, step=10, key="rf_n_estimators")
        max_depth = st.slider("ƒê·ªô s√¢u t·ªëi ƒëa", 1, 20, 10, step=1, key="rf_max_depth")
        model_params = {"n_estimators": n_estimators, "max_depth": max_depth, "random_state": 42}
    elif model_choice == "Logistic Regression":
        C = st.slider("C∆∞·ªùng ƒë·ªô ƒëi·ªÅu ch·ªânh (C)", 0.01, 10.0, 1.0, step=0.01, key="lr_C")
        max_iter = st.slider("S·ªë v√≤ng l·∫∑p t·ªëi ƒëa", 100, 1000, 100, step=100, key="lr_max_iter")
        model_params = {"C": C, "max_iter": max_iter, "random_state": 42}
    elif model_choice == "Polynomial Regression":
        degree = st.slider("B·∫≠c ƒëa th·ª©c", 1, 5, 2, step=1, key="poly_degree")
        C = st.slider("C∆∞·ªùng ƒë·ªô ƒëi·ªÅu ch·ªânh (C)", 0.01, 10.0, 1.0, step=0.01, key="poly_C")
        model_params = {"degree": degree, "C": C, "random_state": 42}

    if st.button("Hu·∫•n luy·ªán m√¥ h√¨nh"):
        with st.spinner("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh..."):
            if use_cv and 'fold_configs' in st.session_state and st.session_state['fold_configs']:
                all_X_train = pd.concat([config['X_train'] for config in st.session_state['fold_configs'].values()])
                all_y_train = pd.concat([config['y_train'] for config in st.session_state['fold_configs'].values()])
                all_X_valid = pd.concat([config['X_valid'] for config in st.session_state['fold_configs'].values()])
                all_y_valid = pd.concat([config['y_valid'] for config in st.session_state['fold_configs'].values()])

                X_train = all_X_train.reset_index(drop=True)
                X_valid = all_X_valid.reset_index(drop=True)
                y_train = all_y_train.reset_index(drop=True)
                y_valid = all_y_valid.reset_index(drop=True)
                train_source = "T·∫•t c·∫£ c√°c fold (ƒë√£ t√πy ch·ªânh)"
            else:
                X_train = st.session_state['X_train_initial']
                X_valid = st.session_state['X_valid']
                y_train = st.session_state['y_train_initial']
                y_valid = st.session_state['y_valid']
                train_source = "D·ªØ li·ªáu ban ƒë·∫ßu"

            # Hu·∫•n luy·ªán m√¥ h√¨nh c·ª•c b·ªô tr∆∞·ªõc khi logging
            if model_choice == "Random Forest":
                model = RandomForestClassifier(**model_params)
            elif model_choice == "Logistic Regression":
                model = LogisticRegression(**model_params)
            elif model_choice == "Polynomial Regression":
                model = Pipeline([
                    ("poly", PolynomialFeatures(degree=model_params["degree"])),
                    ("logistic", LogisticRegression(C=model_params["C"], random_state=42))
                ])

            model.fit(X_train, y_train)
            train_score = model.score(X_train, y_train)
            valid_score = model.score(X_valid, y_valid)

            st.write(f"M√¥ h√¨nh ƒë√£ ch·ªçn: {model_choice}")
            st.write(f"Ngu·ªìn d·ªØ li·ªáu hu·∫•n luy·ªán: {train_source}")
            st.write(f"Tham s·ªë: {model_params}")
            st.write(f"ƒê·ªô ch√≠nh x√°c hu·∫•n luy·ªán: {train_score:.4f}")
            st.write(f"ƒê·ªô ch√≠nh x√°c validation: {valid_score:.4f}")
            st.success(f"Hu·∫•n luy·ªán {model_choice} ho√†n t·∫•t c·ª•c b·ªô ‚úÖ.")

            # Logging v√† tracking v√†o MLflow tr√™n DagsHub
            with mlflow.start_run(run_name=f"{model_choice}_Titanic") as run:
                mlflow.log_params(model_params)
                mlflow.log_param("train_source", train_source)
                mlflow.log_metric("train_accuracy", train_score)
                mlflow.log_metric("valid_accuracy", valid_score)
                mlflow.sklearn.log_model(model, "model")
                run_id = run.info.run_id
                mlflow_uri = st.session_state['mlflow_url']
                st.success(f"Hu·∫•n luy·ªán {model_choice} ho√†n t·∫•t v√† log v√†o MLflow ‚úÖ.")
                st.markdown(f"Xem chi ti·∫øt t·∫°i: [DagsHub MLflow Tracking]({mlflow_uri})")

                # L∆∞u m√¥ h√¨nh v√†o st.session_state ƒë·ªÉ s·ª≠ d·ª•ng trong demo.py
                st.session_state['model'] = model
                st.info("M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c l∆∞u v√†o session ƒë·ªÉ s·ª≠ d·ª•ng trong 'D·ª± ƒëo√°n'.")

if __name__ == "__main__":
    train_model()