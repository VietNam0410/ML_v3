import streamlit as st
import pandas as pd
import mlflow
import mlflow.sklearn
from sklearn.model_selection import train_test_split, KFold
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from common.utils import load_data
import os

# Thi·∫øt l·∫≠p tracking URI c·ª•c b·ªô
mlflow.set_tracking_uri(f"file://{os.path.abspath('mlruns')}")

def train_model():
    st.header("Train Titanic Survival Model üßë‚ÄçüöÄ")

    # Cho ng∆∞·ªùi d√πng ƒë·∫∑t t√™n Experiment
    experiment_name = st.text_input("Enter Experiment Name for Training", value="Titanic_Training")
    if experiment_name:
        mlflow.set_experiment(experiment_name)

     # ƒê·ªçc file ƒë√£ ti·ªÅn x·ª≠ l√Ω
    processed_file = "exercises/exercise_1/data/processed/titanic_processed.csv"
    try:
        data = load_data(processed_file)
        st.subheader("D·ªØ li·ªáu ƒë√£ ti·ªÅn x·ª≠ l√Ω (Sau khi x·ª≠ l√Ω) üìù")
        st.write("ƒê√¢y l√† d·ªØ li·ªáu sau c√°c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω trong 'Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu Titanic':")
        st.write(data.head())
    except FileNotFoundError:
        st.error("D·ªØ li·ªáu ƒë√£ x·ª≠ l√Ω kh√¥ng t√¨m th·∫•y. Vui l√≤ng ho√†n t·∫•t ti·ªÅn x·ª≠ l√Ω trong 'Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu Titanic' tr∆∞·ªõc.")
        return

    # Chia d·ªØ li·ªáu th√†nh X v√† y
    X = data.drop(columns=['Survived'])
    y = data['Survived']

    # 1. Chia d·ªØ li·ªáu train/test/validation
    st.subheader("Chia d·ªØ li·ªáu üîÄ")
    test_size = st.slider("Ch·ªçn k√≠ch th∆∞·ªõc t·∫≠p ki·ªÉm tra (%)", min_value=10, max_value=50, value=20, step=5) / 100
    remaining_size = 1 - test_size
    valid_size_relative = st.slider(
        "Ch·ªçn k√≠ch th∆∞·ªõc t·∫≠p validation (% d·ªØ li·ªáu c√≤n l·∫°i sau khi chia test)",
        min_value=0, max_value=50, value=20, step=5
    ) / 100
    valid_size = remaining_size * valid_size_relative
    train_size = remaining_size - valid_size

    if st.button("Chia d·ªØ li·ªáu"):
        X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=test_size, random_state=42)
        X_train, X_valid, y_train, y_valid = train_test_split(X_temp, y_temp, test_size=valid_size / (1 - test_size), random_state=42)

        # Hi·ªÉn th·ªã k·∫øt qu·∫£ chia d·ªØ li·ªáu
        st.write(f"T·∫≠p hu·∫•n luy·ªán: {len(X_train)} m·∫´u ({train_size*100:.1f}%)")
        st.write(f"T·∫≠p validation: {len(X_valid)} m·∫´u ({valid_size*100:.1f}%)")
        st.write(f"T·∫≠p ki·ªÉm tra: {len(X_test)} m·∫´u ({test_size*100:.1f}%)")
        st.write("D·ªØ li·ªáu hu·∫•n luy·ªán (X_train):", X_train.head())
        st.write("D·ªØ li·ªáu validation (X_valid):", X_valid.head())
        st.write("D·ªØ li·ªáu ki·ªÉm tra (X_test):", X_test.head())

        # Ki·ªÉm tra v√† k·∫øt th√∫c run hi·ªán t·∫°i n·∫øu c√≥
        # S·ª≠a ƒë·ªïi b·ªüi Grok 3: Th√™m ki·ªÉm tra run hi·ªán t·∫°i v√† k·∫øt th√∫c n·∫øu c·∫ßn
        active_run = mlflow.active_run()
        if active_run:
            mlflow.end_run()

        # Log th√¥ng tin d·ªØ li·ªáu chi ti·∫øt
        with mlflow.start_run(run_name="Data_Split"):
            mlflow.log_param("data_shape", data.shape)
            mlflow.log_param("test_size", test_size)
            mlflow.log_param("valid_size", valid_size)
            mlflow.log_param("train_size", train_size)
            mlflow.log_text(X_train.head().to_csv(), "X_train_sample.csv")
            mlflow.log_text(X_valid.head().to_csv(), "X_valid_sample.csv")
            mlflow.log_text(X_test.head().to_csv(), "X_test_sample.csv")
            st.success("D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia v√† log v√†o MLflow ‚úÖ.")

        # L∆∞u d·ªØ li·ªáu v√†o session ƒë·ªÉ d√πng sau
        st.session_state['X_train'] = X_train
        st.session_state['X_valid'] = X_valid
        st.session_state['X_test'] = X_test
        st.session_state['y_train'] = y_train
        st.session_state['y_valid'] = y_valid
        st.session_state['y_test'] = y_test

    # 2. Cross Validation
    st.subheader("Cross Validation (T√πy ch·ªçn) üîÑ")
    use_cv = st.checkbox("S·ª≠ d·ª•ng Cross Validation")
    if use_cv:
        k_folds = st.slider("Ch·ªçn s·ªë l∆∞·ª£ng folds (k)", min_value=2, max_value=10, value=5)
        if st.button("T·∫°o Cross Validation Folds"):
            kf = KFold(n_splits=k_folds, shuffle=True, random_state=42)
            fold_data = []
            for fold, (train_idx, valid_idx) in enumerate(kf.split(X)):
                fold_data.append({
                    "fold": fold + 1,
                    "train_size": len(train_idx),
                    "valid_size": len(valid_idx)
                })
            fold_df = pd.DataFrame(fold_data)
            st.write("Cross Validation Folds:", fold_df)

            # Ki·ªÉm tra v√† k·∫øt th√∫c run hi·ªán t·∫°i n·∫øu c√≥
            # S·ª≠a ƒë·ªïi b·ªüi Grok 3: Th√™m ki·ªÉm tra run hi·ªán t·∫°i v√† k·∫øt th√∫c n·∫øu c·∫ßn
            active_run = mlflow.active_run()
            if active_run:
                mlflow.end_run()

            # Log chi ti·∫øt cross-validation
            with mlflow.start_run(run_name=f"CV_{k_folds}_Folds", nested=True):  # S·ª≠ d·ª•ng nested=True cho run l·ªìng nhau
                mlflow.log_param("k_folds", k_folds)
                for _, row in fold_df.iterrows():
                    mlflow.log_metric(f"fold_{row['fold']}_train_size", row["train_size"])
                    mlflow.log_metric(f"fold_{row['fold']}_valid_size", row["valid_size"])
                st.success(f"T·∫°o {k_folds}-fold cross validation v√† log v√†o MLflow ‚úÖ.")

    # 3. Hu·∫•n luy·ªán m√¥ h√¨nh
    st.subheader("Hu·∫•n luy·ªán m√¥ h√¨nh üéØ")
    if 'X_train' not in st.session_state:
        st.warning("Vui l√≤ng chia d·ªØ li·ªáu tr∆∞·ªõc khi hu·∫•n luy·ªán.")
        return

    model_choice = st.selectbox(
        "Ch·ªçn m√¥ h√¨nh",
        ["Random Forest", "Logistic Regression", "Polynomial Regression"]
    )

    # Tham s·ªë cho t·ª´ng m√¥ h√¨nh
    if model_choice == "Random Forest":
        n_estimators = st.slider("S·ªë l∆∞·ª£ng c√¢y (n_estimators)", 10, 200, 100, step=10)
        max_depth = st.slider("ƒê·ªô s√¢u t·ªëi ƒëa", 1, 20, 10, step=1)
        model_params = {"n_estimators": n_estimators, "max_depth": max_depth, "random_state": 42}
    elif model_choice == "Logistic Regression":
        C = st.slider("C∆∞·ªùng ƒë·ªô ƒëi·ªÅu ch·ªânh (C)", 0.01, 10.0, 1.0, step=0.01)
        max_iter = st.slider("S·ªë v√≤ng l·∫∑p t·ªëi ƒëa", 100, 1000, 100, step=100)
        model_params = {"C": C, "max_iter": max_iter, "random_state": 42}
    elif model_choice == "Polynomial Regression":
        degree = st.slider("B·∫≠c ƒëa th·ª©c", 1, 5, 2, step=1)
        C = st.slider("C∆∞·ªùng ƒë·ªô ƒëi·ªÅu ch·ªânh (C)", 0.01, 10.0, 1.0, step=0.01)
        model_params = {"degree": degree, "C": C, "random_state": 42}

    if st.button("Hu·∫•n luy·ªán m√¥ h√¨nh"):
        X_train = st.session_state['X_train']
        X_valid = st.session_state['X_valid']
        y_train = st.session_state['y_train']
        y_valid = st.session_state['y_valid']

        # Ki·ªÉm tra v√† k·∫øt th√∫c run hi·ªán t·∫°i n·∫øu c√≥
        # S·ª≠a ƒë·ªïi b·ªüi Grok 3: Th√™m ki·ªÉm tra run hi·ªán t·∫°i v√† k·∫øt th√∫c n·∫øu c·∫ßn
        active_run = mlflow.active_run()
        if active_run:
            mlflow.end_run()

        with mlflow.start_run(run_name=f"{model_choice}_Titanic"):
            # Kh·ªüi t·∫°o m√¥ h√¨nh d·ª±a tr√™n l·ª±a ch·ªçn
            if model_choice == "Random Forest":
                model = RandomForestClassifier(**model_params)
            elif model_choice == "Logistic Regression":
                model = LogisticRegression(**model_params)
            elif model_choice == "Polynomial Regression":
                model = Pipeline([
                    ("poly", PolynomialFeatures(degree=model_params["degree"])),
                    ("logistic", LogisticRegression(C=model_params["C"], random_state=42))
                ])

            # Hu·∫•n luy·ªán m√¥ h√¨nh
            model.fit(X_train, y_train)
            train_score = model.score(X_train, y_train)
            valid_score = model.score(X_valid, y_valid)

            # T√≠nh to√°n v√† log th√™m metrics
            y_train_pred = model.predict(X_train)
            y_valid_pred = model.predict(X_valid)

            metrics = {
                "train_accuracy": accuracy_score(y_train, y_train_pred),
                "valid_accuracy": accuracy_score(y_valid, y_valid_pred),
                "train_precision": precision_score(y_train, y_train_pred, average='weighted'),
                "valid_precision": precision_score(y_valid, y_valid_pred, average='weighted'),
                "train_recall": recall_score(y_train, y_train_pred, average='weighted'),
                "valid_recall": recall_score(y_valid, y_valid_pred, average='weighted'),
                "train_f1": f1_score(y_train, y_train_pred, average='weighted'),
                "valid_f1": f1_score(y_valid, y_valid_pred, average='weighted')
            }

            # Hi·ªÉn th·ªã th√¥ng tin
            st.write(f"M√¥ h√¨nh ƒë√£ ch·ªçn: {model_choice}")
            st.write(f"Tham s·ªë: {model_params}")
            st.write(f"ƒê·ªô ch√≠nh x√°c hu·∫•n luy·ªán: {train_score:.4f}")
            st.write(f"ƒê·ªô ch√≠nh x√°c validation: {valid_score:.4f}")

            # Log v√†o MLflow
            mlflow.log_params(model_params)
            for metric, value in metrics.items():
                mlflow.log_metric(metric, value)
            
            # Log m√¥ h√¨nh v·ªõi input example ƒë·ªÉ t·ª± ƒë·ªông infer signature
            mlflow.sklearn.log_model(model, "model", input_example=X_train.iloc[:1])
            st.success(f"Hu·∫•n luy·ªán {model_choice} ho√†n t·∫•t v√† log chi ti·∫øt v√†o MLflow ‚úÖ.")

if __name__ == "__main__":
    train_model()