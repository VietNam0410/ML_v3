import os
import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import Callback
import mlflow
import mlflow.keras
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split
from datetime import datetime

# Thi·∫øt l·∫≠p MLflow
DAGSHUB_MLFLOW_URI = "https://dagshub.com/VietNam0410/ML_v3.mlflow"
mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
os.environ["MLFLOW_TRACKING_USERNAME"] = "VietNam0410"
os.environ["MLFLOW_TRACKING_PASSWORD"] = "c9db6bdcca1dfed76d2af2cdb15a9277e6732d6b"

# Callback ƒë·ªÉ c·∫≠p nh·∫≠t thanh ti·∫øn tr√¨nh
class ProgressCallback(Callback):
    def __init__(self, total_epochs):
        super().__init__()
        self.total_epochs = total_epochs
        self.progress_bar = st.progress(0)
        self.status_text = st.empty()

    def on_epoch_end(self, epoch, logs=None):
        progress = (epoch + 1) / self.total_epochs
        self.progress_bar.progress(progress)
        self.status_text.text(f"Epoch {epoch + 1}/{self.total_epochs} - Loss: {logs['loss']:.4f} - Accuracy: {logs['accuracy']:.4f}")

# H√†m x·ª≠ l√Ω ·∫£nh
def preprocess_image(image):
    image = image.astype('float32') / 255.0
    image = image.reshape(-1, 28, 28)
    return image

# H√†m ch·ªçn d·ªØ li·ªáu ban ƒë·∫ßu d·ª±a tr√™n s·ªë l∆∞·ª£ng m·∫´u ho·∫∑c t·ª∑ l·ªá
def select_initial_data(X, y, labeled_ratio=0.01):
    X_selected = []
    y_selected = []
    for digit in range(10):
        indices = np.where(y == digit)[0]
        num_samples = max(1, int(len(indices) * labeled_ratio))  # ƒê·∫£m b·∫£o √≠t nh·∫•t 1 m·∫´u m·ªói class
        selected_indices = np.random.choice(indices, num_samples, replace=False)
        X_selected.append(X[selected_indices])
        y_selected.append(y[selected_indices])
    return np.concatenate(X_selected), np.concatenate(y_selected)

# H√†m hi·ªÉn th·ªã v√≠ d·ª• ·∫£nh ƒë∆∞·ª£c g√°n nh√£n gi·∫£
def display_pseudo_labeled_examples(X_unlabeled, y_unlabeled_true, pseudo_labels, confidences, high_confidence_indices, iteration):
    st.subheader(f"V√≠ d·ª• m·ªôt s·ªë m·∫´u ƒë∆∞·ª£c g√°n nh√£n gi·∫£ trong v√≤ng l·∫∑p {iteration + 1}")
    num_examples = min(5, len(high_confidence_indices))
    if num_examples == 0:
        st.write("Kh√¥ng c√≥ m·∫´u n√†o v∆∞·ª£t ng∆∞·ª°ng ƒë·ªô tin c·∫≠y v√† ƒë∆∞·ª£c g√°n ƒë√∫ng trong v√≤ng l·∫∑p n√†y.")
        return
        
    sample_indices = np.random.choice(high_confidence_indices, num_examples, replace=False)
    
    cols = st.columns(num_examples)
    for i, idx in enumerate(sample_indices):
        if idx >= len(X_unlabeled):
            st.warning(f"Ch·ªâ s·ªë {idx} v∆∞·ª£t qu√° k√≠ch th∆∞·ªõc c·ªßa X_unlabeled ({len(X_unlabeled)}). B·ªè qua m·∫´u n√†y.")
            continue
            
        img = X_unlabeled[idx].reshape(28, 28)
        pred_label = pseudo_labels[idx]
        true_label = y_unlabeled_true[idx]
        conf = confidences[idx]
        
        with cols[i]:
            fig, ax = plt.subplots(figsize=(3, 3))
            ax.imshow(img, cmap='gray')
            ax.axis('off')
            ax.set_title(f"Pred: {pred_label}\nTrue: {true_label}\nConf: {conf:.2f}")
            st.pyplot(fig)

# H√†m hu·∫•n luy·ªán v·ªõi Pseudo Labeling
def train_mnist_pseudo_labeling(X_full, y_full):
    st.title("üß† Hu·∫•n Luy·ªán Neural Network v·ªõi Pseudo Labeling")

    # Kh·ªüi t·∫°o session state cho learning rate
    if 'learning_rate' not in st.session_state:
        st.session_state['learning_rate'] = 0.001  # Gi√° tr·ªã m·∫∑c ƒë·ªãnh h·ª£p l√Ω

    # B∆∞·ªõc 1: Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u v√† chia t·∫≠p d·ªØ li·ªáu
    st.subheader("1. Ch·ªçn S·ªë L∆∞·ª£ng M·∫´u v√† Chia T·∫≠p D·ªØ Li·ªáu")
    num_samples = st.number_input("S·ªë m·∫´u (0-70000)", min_value=0, max_value=len(X_full), value=min(10000, len(X_full)), step=1000,
                                  help=f"S·ªë l∆∞·ª£ng m·∫´u ƒë·ªÉ hu·∫•n luy·ªán (t·ªëi ƒëa {len(X_full)}).")
    if num_samples == 0:
        st.error("S·ªë m·∫´u ph·∫£i l·ªõn h∆°n 0!")
        return

    # L·∫•y m·∫´u t·ª´ d·ªØ li·ªáu g·ªëc
    indices = np.random.choice(len(X_full), num_samples, replace=False)
    X_selected, y_selected = X_full[indices], y_full[indices]

    st.subheader("2. Ph√¢n Chia T·∫≠p D·ªØ Li·ªáu")
    test_ratio = st.number_input("T·ª∑ l·ªá t·∫≠p Test (%)", min_value=10.0, max_value=80.0, value=20.0, step=1.0,
                                 help="T·ª∑ l·ªá d·ªØ li·ªáu d√πng ƒë·ªÉ test (10-80%).")
    val_ratio = st.number_input("T·ª∑ l·ªá Validation (%)", min_value=0.0, max_value=80.0 - test_ratio, value=10.0, step=1.0,
                                help="T·ª∑ l·ªá d·ªØ li·ªáu d√πng ƒë·ªÉ validation (ph·∫ßn c√≤n l·∫°i l√† t·∫≠p train).")
    train_ratio = 100.0 - test_ratio - val_ratio
    if train_ratio <= 0:
        st.error("T·ª∑ l·ªá Train ph·∫£i l·ªõn h∆°n 0! Gi·∫£m t·ª∑ l·ªá Test ho·∫∑c Validation.")
        return

    test_size = test_ratio / 100.0
    val_size = val_ratio / (train_ratio + val_ratio) if (train_ratio + val_ratio) > 0 else 0
    X_temp, X_test, y_temp, y_test = train_test_split(X_selected, y_selected, test_size=test_size, random_state=42, stratify=y_selected)
    X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=val_size, random_state=42, stratify=y_temp)

    st.write(f"S·ªë m·∫´u: Train {len(X_train)}, Validation {len(X_val)}, Test {len(X_test)}")

    # Chu·∫©n h√≥a d·ªØ li·ªáu
    X_train = preprocess_image(X_train)
    X_val = preprocess_image(X_val)
    X_test = preprocess_image(X_test)
    y_train_cat = to_categorical(y_train, 10)
    y_val_cat = to_categorical(y_val, 10)
    y_test_cat = to_categorical(y_test, 10)

    # B∆∞·ªõc 2: L·∫•y d·ªØ li·ªáu ban ƒë·∫ßu (1% l√†m labeled)
    labeled_ratio = 0.01
    X_labeled, y_labeled = select_initial_data(X_train, y_train, labeled_ratio)
    y_labeled_cat = to_categorical(y_labeled, 10)
    st.write(f"S·ªë m·∫´u ƒë∆∞·ª£c g√°n nh√£n ban ƒë·∫ßu (1% m·ªói class): {len(X_labeled)}")

    # T·∫°o t·∫≠p d·ªØ li·ªáu ch∆∞a ƒë∆∞·ª£c g√°n nh√£n (99% c√≤n l·∫°i)
    labeled_indices = np.random.choice(len(X_train), len(X_labeled), replace=False)
    unlabeled_indices = np.setdiff1d(np.arange(len(X_train)), labeled_indices)
    X_unlabeled = X_train[unlabeled_indices]
    y_unlabeled_true = y_train[unlabeled_indices]
    st.write(f"S·ªë m·∫´u ch∆∞a ƒë∆∞·ª£c g√°n nh√£n: {len(X_unlabeled)}")

    # B∆∞·ªõc 3: Thi·∫øt l·∫≠p tham s·ªë Neural Network
    st.subheader("3. Thi·∫øt L·∫≠p Tham S·ªë Neural Network")
    col1, col2 = st.columns(2)
    with col1:
        n_hidden_layers = st.number_input("S·ªë l·ªõp ·∫©n", min_value=1, max_value=5, value=2, step=1,
                                        help="S·ªë l∆∞·ª£ng l·ªõp ·∫©n (2-3 l√† ƒë·ªß cho MNIST).")
        neurons_per_layer = st.number_input("S·ªë n∆°-ron m·ªói l·ªõp", min_value=16, max_value=512, value=128, step=16,
                                          help="S·ªë n∆°-ron trong m·ªói l·ªõp ·∫©n (128-256 l√† ph·ªï bi·∫øn).")
        epochs = st.number_input("S·ªë v√≤ng l·∫∑p (epochs)", min_value=1, max_value=50, value=10, step=1,
                               help="S·ªë l·∫ßn hu·∫•n luy·ªán to√†n b·ªô d·ªØ li·ªáu (5-10 l√† h·ª£p l√Ω).")
    with col2:
        batch_size = st.number_input("K√≠ch th∆∞·ªõc batch", min_value=16, max_value=256, value=32, step=16,
                                   help="K√≠ch th∆∞·ªõc batch cho m·ªói l·∫ßn c·∫≠p nh·∫≠t tr·ªçng s·ªë (32-64 l√† t·ªët).")
        learning_rate = st.number_input("T·ªëc ƒë·ªô h·ªçc (Œ∑)", min_value=0.00001, max_value=0.01, value=float(st.session_state['learning_rate']), step=0.0001,
                                      help="T·ªëc ƒë·ªô h·ªçc (0.001-0.01, nh·ªè h∆°n ƒë·ªÉ h·ªçc ·ªïn ƒë·ªãnh).", key="learning_rate_input")
        activation = st.selectbox("H√†m k√≠ch ho·∫°t", ['relu', 'sigmoid', 'tanh'], index=0,
                                help="'relu' th∆∞·ªùng hi·ªáu qu·∫£ nh·∫•t cho MNIST.")

    # C·∫≠p nh·∫≠t learning_rate trong session state
    if learning_rate != st.session_state['learning_rate']:
        st.session_state['learning_rate'] = learning_rate
        st.write(f"ƒê√£ c·∫≠p nh·∫≠t t·ªëc ƒë·ªô h·ªçc: **{learning_rate}**")

    # B∆∞·ªõc 4: Thi·∫øt l·∫≠p tham s·ªë Pseudo Labeling
    st.subheader("4. Thi·∫øt L·∫≠p Tham S·ªë Pseudo Labeling")
    max_iterations = st.number_input("S·ªë b∆∞·ªõc l·∫∑p t·ªëi ƒëa", min_value=1, max_value=20, value=10, step=1,
                                   help="S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa cho qu√° tr√¨nh g√°n nh√£n gi·∫£ (5-10 l√† ƒë·ªß).")
    threshold = st.number_input("Ng∆∞·ª°ng ƒë·ªô tin c·∫≠y", min_value=0.5, max_value=1.0, value=0.95, step=0.01,
                              help="Ng∆∞·ª°ng ƒë·ªô tin c·∫≠y ƒë·ªÉ g√°n nh√£n gi·∫£ (0.9-0.95 l√† t·ªët).")

    # T√πy ch·ªânh t√™n run
    st.subheader("5. T√πy Ch·ªânh T√™n Run")
    run_name = st.text_input("T√™n Run (ƒë·ªÉ tr·ªëng ƒë·ªÉ t·ª± ƒë·ªông t·∫°o)", value="")
    if not run_name:
        run_name = f"PseudoLabel_{num_samples}_{test_ratio}_{val_ratio}_{n_hidden_layers}_{max_iterations}_{threshold}"

    # Kh·ªüi t·∫°o m√¥ h√¨nh
    try:
        model = Sequential()
        model.add(Flatten(input_shape=(28, 28)))
        for _ in range(n_hidden_layers):
            model.add(Dense(neurons_per_layer, activation=activation))
        model.add(Dense(10, activation='softmax'))
        optimizer = Adam(learning_rate=learning_rate)
        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])
    except Exception as e:
        st.error(f"L·ªói khi x√¢y d·ª±ng m√¥ h√¨nh: {str(e)}")
        return

    # Hu·∫•n luy·ªán v·ªõi Pseudo Labeling
    if st.button("B·∫Øt ƒê·∫ßu Hu·∫•n Luy·ªán v·ªõi Pseudo Labeling"):
        mlflow.set_experiment("MNIST_Pseudo_Labeling")
        with mlflow.start_run(run_name=run_name) as run:
            run_id = run.info.run_id

            # V√≤ng l·∫∑p Pseudo Labeling
            X_current = X_labeled.copy()
            y_current = y_labeled_cat.copy()
            iteration = 0
            total_iterations = 0
            history_iterations = []
            
            # Th√™m bi·∫øn theo d√µi
            labeled_counts = [len(X_labeled)]
            unlabeled_counts = [len(X_unlabeled)]
            correct_counts = [0]  # S·ªë l∆∞·ª£ng m·∫´u g√°n ƒë√∫ng
            confidence_means = []
            correct_ratios = []
            test_accuracies = []
            val_accuracies = []
            additional_epochs = 0  # Kh·ªüi t·∫°o m·∫∑c ƒë·ªãnh
            final_val_acc = 0.0  # Kh·ªüi t·∫°o m·∫∑c ƒë·ªãnh
            final_test_acc = 0.0  # Kh·ªüi t·∫°o m·∫∑c ƒë·ªãnh

            # T·∫°o container ƒë·ªÉ hi·ªÉn th·ªã ti·∫øn tr√¨nh
            progress_container = st.empty()
            
            # Giai ƒëo·∫°n 1: G√°n nh√£n gi·∫£ l·∫∑p l·∫°i
            while len(X_unlabeled) > 0 and iteration < max_iterations:
                with progress_container.container():
                    st.write(f"**V√≤ng l·∫∑p G√°n Nh√£n {iteration + 1}/{max_iterations}**")
                    st.write(f"S·ªë m·∫´u hu·∫•n luy·ªán hi·ªán t·∫°i: {len(X_current)}")
                    st.write(f"Ng∆∞·ª°ng ƒë·ªô tin c·∫≠y hi·ªán t·∫°i: {threshold:.4f}")

                    # B∆∞·ªõc 2: Hu·∫•n luy·ªán m√¥ h√¨nh tr√™n t·∫≠p d·ªØ li·ªáu hi·ªán t·∫°i (1% ban ƒë·∫ßu + d·ªØ li·ªáu g√°n nh√£n gi·∫£)
                    progress_callback = ProgressCallback(epochs)
                    history = model.fit(X_current, y_current, epochs=epochs, batch_size=batch_size, verbose=0,
                                        validation_data=(X_val, y_val_cat), callbacks=[progress_callback])
                    history_iterations.append(history.history)

                    # ƒê√°nh gi√° tr√™n t·∫≠p validation v√† test
                    _, val_acc = model.evaluate(X_val, y_val_cat, verbose=0)
                    _, test_acc = model.evaluate(X_test, y_test_cat, verbose=0)
                    val_accuracies.append(val_acc)
                    test_accuracies.append(test_acc)
                    st.write(f"ƒê·ªô ch√≠nh x√°c Validation: {val_acc:.4f}")
                    st.write(f"ƒê·ªô ch√≠nh x√°c Test: {test_acc:.4f}")

                    # B∆∞·ªõc 3: D·ª± ƒëo√°n nh√£n cho d·ªØ li·ªáu ch∆∞a g√°n nh√£n (99% c√≤n l·∫°i ban ƒë·∫ßu)
                    predictions = model.predict(X_unlabeled)
                    confidences = np.max(predictions, axis=1)
                    pseudo_labels = np.argmax(predictions, axis=1)
                    
                    # T√≠nh ƒë·ªô tin c·∫≠y trung b√¨nh
                    confidence_mean = np.mean(confidences)
                    confidence_means.append(confidence_mean)
                    st.write(f"ƒê·ªô tin c·∫≠y trung b√¨nh: {confidence_mean:.4f}")

                    # T√≠nh s·ªë l∆∞·ª£ng v√† t·ª∑ l·ªá nh√£n gi·∫£ ƒë√∫ng
                    correct_count = np.sum(pseudo_labels == y_unlabeled_true)
                    correct_counts.append(correct_count)
                    correct_ratio = correct_count / len(pseudo_labels) if len(pseudo_labels) > 0 else 0
                    correct_ratios.append(correct_ratio)
                    st.write(f"S·ªë l∆∞·ª£ng m·∫´u g√°n ƒë√∫ng: {correct_count}")
                    st.write(f"T·ª∑ l·ªá nh√£n gi·∫£ ƒë√∫ng: {correct_ratio:.4f}")

                    # C·∫£nh b√°o n·∫øu t·ª∑ l·ªá nh√£n gi·∫£ ƒë√∫ng th·∫•p
                    if correct_ratio < 0.7 and iteration > 0:
                        st.warning("T·ª∑ l·ªá nh√£n gi·∫£ ƒë√∫ng qu√° th·∫•p (< 70%). H√£y xem x√©t gi·∫£m learning rate ho·∫∑c tƒÉng ng∆∞·ª°ng ƒë·ªô tin c·∫≠y.")

                    # B∆∞·ªõc 4: L·ªçc c√°c m·∫´u g√°n ƒë√∫ng v√† v∆∞·ª£t ng∆∞·ª°ng
                    correct_and_confident_indices = np.where((confidences >= threshold) & (pseudo_labels == y_unlabeled_true))[0]
                    if len(correct_and_confident_indices) == 0 and iteration < max_iterations - 1:
                        st.warning("Kh√¥ng c√≥ m·∫´u n√†o v∆∞·ª£t ng∆∞·ª°ng v√† ƒë∆∞·ª£c g√°n ƒë√∫ng. Gi·∫£m ng∆∞·ª°ng ho·∫∑c ki·ªÉm tra m√¥ h√¨nh.")
                    elif len(correct_and_confident_indices) == 0 and iteration == max_iterations - 1:
                        st.warning("G√°n t·∫•t c·∫£ m·∫´u c√≤n l·∫°i v·ªõi ng∆∞·ª°ng hi·ªán t·∫°i (kh√¥ng ki·ªÉm tra ƒë√∫ng sai).")
                        correct_and_confident_indices = np.arange(len(X_unlabeled))

                    X_pseudo = X_unlabeled[correct_and_confident_indices]
                    y_pseudo = pseudo_labels[correct_and_confident_indices]
                    y_pseudo_cat = to_categorical(y_pseudo, 10)

                    # B∆∞·ªõc 5: C·∫≠p nh·∫≠t t·∫≠p d·ªØ li·ªáu hu·∫•n luy·ªán (t·∫≠p 1% ban ƒë·∫ßu + d·ªØ li·ªáu v·ª´a g√°n)
                    X_current = np.concatenate([X_current, X_pseudo])
                    y_current = np.concatenate([y_current, y_pseudo_cat])

                    # Lo·∫°i b·ªè c√°c m·∫´u ƒë√£ ƒë∆∞·ª£c g√°n nh√£n kh·ªèi t·∫≠p ch∆∞a g√°n nh√£n
                    remaining_indices = np.setdiff1d(np.arange(len(X_unlabeled)), correct_and_confident_indices)
                    X_unlabeled = X_unlabeled[remaining_indices] if len(remaining_indices) > 0 else np.array([])
                    y_unlabeled_true = y_unlabeled_true[remaining_indices] if len(remaining_indices) > 0 else np.array([])

                    # Hi·ªÉn th·ªã v√≠ d·ª•
                    display_pseudo_labeled_examples(X_unlabeled, y_unlabeled_true, pseudo_labels, confidences, correct_and_confident_indices, iteration)

                    # C·∫≠p nh·∫≠t s·ªë l∆∞·ª£ng
                    labeled_counts.append(len(X_current))
                    unlabeled_counts.append(len(X_unlabeled))
                    iteration += 1

            # Ki·ªÉm tra ch√≠nh x√°c cu·ªëi c√πng tr√™n to√†n b·ªô t·∫≠p train
            final_predictions = model.predict(X_train)
            final_pseudo_labels = np.argmax(final_predictions, axis=1)
            final_correct_count = np.sum(final_pseudo_labels == y_train)
            final_accuracy = final_correct_count / len(y_train)
            st.success(f"ƒê√£ ho√†n th√†nh g√°n nh√£n sau {iteration} v√≤ng l·∫∑p.")
            st.write(f"T·ªïng s·ªë m·∫´u g√°n ƒë√∫ng tr√™n to√†n b·ªô t·∫≠p train: {final_correct_count} / {len(y_train)}")
            st.write(f"T·ª∑ l·ªá g√°n ƒë√∫ng cu·ªëi c√πng: {final_accuracy:.4f}")

            # Giai ƒëo·∫°n 2: Hu·∫•n luy·ªán b·ªï sung (n·∫øu ƒë·∫°t 100% ch√≠nh x√°c)
            if final_accuracy == 1.0:
                st.subheader("6. Hu·∫•n Luy·ªán B·ªï Sung v·ªõi To√†n B·ªô D·ªØ Li·ªáu")
                additional_epochs = st.number_input("S·ªë epochs b·ªï sung", min_value=1, max_value=50, value=5, step=1,
                                                  help="S·ªë epochs ƒë·ªÉ hu·∫•n luy·ªán th√™m sau khi ƒë·∫°t 100% ch√≠nh x√°c.")
                if additional_epochs > 0:
                    progress_callback = ProgressCallback(additional_epochs)
                    history = model.fit(X_train, y_train_cat, epochs=additional_epochs, batch_size=batch_size, verbose=0,
                                        validation_data=(X_val, y_val_cat), callbacks=[progress_callback])
                    history_iterations.append(history.history)

                    # ƒê√°nh gi√° cu·ªëi c√πng
                    _, final_val_acc = model.evaluate(X_val, y_val_cat, verbose=0)
                    _, final_test_acc = model.evaluate(X_test, y_test_cat, verbose=0)
                    val_accuracies.append(final_val_acc)
                    test_accuracies.append(final_test_acc)
                    st.success(f"ƒê·ªô ch√≠nh x√°c cu·ªëi c√πng - Validation: {final_val_acc:.4f}, Test: {final_test_acc:.4f}")

                    # L∆∞u m√¥ h√¨nh
                    mlflow.keras.log_model(model, "final_model")

            total_iterations = iteration + (additional_epochs > 0 and 1 or 0)
            st.write(f"T·ªïng s·ªë v√≤ng l·∫∑p: {total_iterations}")

            # Bi·ªÉu ƒë·ªì tr·ª±c quan
            st.subheader("7. Bi·ªÉu ƒê·ªì Qu√° Tr√¨nh Hu·∫•n Luy·ªán Pseudo Labeling")

            # Bi·ªÉu ƒë·ªì s·ªë l∆∞·ª£ng m·∫´u
            fig_counts = go.Figure()
            fig_counts.add_trace(go.Scatter(x=list(range(len(labeled_counts))), y=labeled_counts, mode='lines+markers', name='S·ªë m·∫´u ƒë√£ g√°n nh√£n'))
            fig_counts.add_trace(go.Scatter(x=list(range(len(unlabeled_counts))), y=unlabeled_counts, mode='lines+markers', name='S·ªë m·∫´u ch∆∞a g√°n nh√£n'))
            fig_counts.update_layout(title="S·ªë l∆∞·ª£ng m·∫´u qua c√°c v√≤ng l·∫∑p", xaxis_title="V√≤ng l·∫∑p", yaxis_title="S·ªë l∆∞·ª£ng", height=400)
            st.plotly_chart(fig_counts, use_container_width=True)

            # Bi·ªÉu ƒë·ªì ƒë·ªô ch√≠nh x√°c
            fig_acc = go.Figure()
            fig_acc.add_trace(go.Scatter(x=list(range(len(val_accuracies))), y=val_accuracies, mode='lines+markers', name='Validation Accuracy'))
            fig_acc.add_trace(go.Scatter(x=list(range(len(test_accuracies))), y=test_accuracies, mode='lines+markers', name='Test Accuracy'))
            fig_acc.update_layout(title="ƒê·ªô ch√≠nh x√°c qua c√°c v√≤ng l·∫∑p", xaxis_title="V√≤ng l·∫∑p", yaxis_title="ƒê·ªô ch√≠nh x√°c", height=400)
            st.plotly_chart(fig_acc, use_container_width=True)

            # Bi·ªÉu ƒë·ªì s·ªë l∆∞·ª£ng m·∫´u g√°n ƒë√∫ng
            fig_correct = go.Figure()
            fig_correct.add_trace(go.Scatter(x=list(range(len(correct_counts))), y=correct_counts, mode='lines+markers', name='S·ªë m·∫´u g√°n ƒë√∫ng'))
            fig_correct.update_layout(title="S·ªë l∆∞·ª£ng m·∫´u g√°n ƒë√∫ng qua c√°c v√≤ng l·∫∑p", xaxis_title="V√≤ng l·∫∑p", yaxis_title="S·ªë l∆∞·ª£ng", height=400)
            st.plotly_chart(fig_correct, use_container_width=True)

            # Log MLflow
            mlflow.log_params({
                "num_samples": num_samples,
                "test_ratio": test_ratio,
                "val_ratio": val_ratio,
                "train_ratio": train_ratio,
                "labeled_ratio": labeled_ratio,
                "n_hidden_layers": n_hidden_layers,
                "neurons_per_layer": neurons_per_layer,
                "epochs": epochs,
                "batch_size": batch_size,
                "learning_rate": learning_rate,
                "activation": activation,
                "max_iterations": max_iterations,
                "threshold": threshold,
                "labeling_iterations": iteration,
                "total_iterations": total_iterations,
                "log_time": datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            })
            mlflow.log_metrics({
                "final_val_accuracy": float(final_val_acc),
                "final_test_accuracy": float(final_test_acc),
                "final_train_accuracy": float(final_accuracy),
                "total_correct_pseudo_labels": float(sum(correct_counts[1:]))
            })

            # Hi·ªÉn th·ªã th√¥ng tin MLflow
            st.subheader("8. Th√¥ng Tin ƒê∆∞·ª£c Ghi L·∫°i")
            runs = mlflow.search_runs()
            expected_columns = ['params.num_samples', 'params.test_ratio', 'params.val_ratio', 'params.train_ratio',
                              'params.labeled_ratio', 'params.n_hidden_layers', 'params.neurons_per_layer',
                              'params.epochs', 'params.batch_size', 'params.learning_rate', 'params.activation',
                              'params.max_iterations', 'params.threshold',
                              'params.labeling_iterations', 'params.total_iterations', 'params.log_time',
                              'metrics.final_val_accuracy', 'metrics.final_test_accuracy', 'metrics.final_train_accuracy',
                              'metrics.total_correct_pseudo_labels']
            for col in expected_columns:
                if col not in runs.columns:
                    runs[col] = None
            st.dataframe(runs[['run_id'] + expected_columns])

if __name__ == "__main__":
    from tensorflow.keras.datasets import mnist
    (X_full, y_full), (_, _) = mnist.load_data()
    train_mnist_pseudo_labeling(X_full, y_full)