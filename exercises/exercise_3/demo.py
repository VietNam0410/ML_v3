import streamlit as st
import pandas as pd
import mlflow
from mlflow.tracking import MlflowClient
import os
import logging
import numpy as np  # Th√™m import numpy
import datetime  # Th√™m import datetime

# Thi·∫øt l·∫≠p logging ƒë·ªÉ debug n·∫øu c·∫ßn
logging.getLogger("mlflow").setLevel(logging.INFO)

# Thi·∫øt l·∫≠p MLflow v√† DagsHub
DAGSHUB_MLFLOW_URI = "https://dagshub.com/VietNam0410/ML_v3.mlflow"
mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
os.environ["MLFLOW_TRACKING_USERNAME"] = "VietNam0410"
os.environ["MLFLOW_TRACKING_PASSWORD"] = "c9db6bdcca1dfed76d2af2cdb15a9277e6732d6b"

# H√†m hi·ªÉn th·ªã v√† x√≥a log t·ª´ experiment, x·ª≠ l√Ω l·ªói ki·ªÉu d·ªØ li·ªáu
@st.cache_data
def display_logs(_client, experiment_name):
    experiment = _client.get_experiment_by_name(experiment_name)
    if not experiment:
        st.warning(f"Ch∆∞a c√≥ experiment '{experiment_name}'. S·∫Ω t·∫°o khi c√≥ log ƒë·∫ßu ti√™n.")
        return None, None
    
    runs = _client.search_runs(experiment_ids=[experiment.experiment_id])
    if not runs:
        st.warning(f"Kh√¥ng c√≥ log n√†o trong experiment '{experiment_name}'.")
        return None, None
    
    data = []
    for run in runs:
        run_name = run.data.tags.get("mlflow.runName", run.info.run_id)
        model_type = run.data.params.get("model_type", "N/A")
        timestamp = run.data.params.get("timestamp", "N/A")
        if experiment_name == "MNIST_Train_Clustering":
            n_clusters = run.data.metrics.get("n_clusters_found", np.nan)
            silhouette = run.data.metrics.get("silhouette_valid", np.nan)
            silhouette_value = float(silhouette) if not pd.isna(silhouette) else np.nan
            data.append({
                "T√™n Run": run_name,
                "Lo·∫°i M√¥ h√¨nh": model_type,
                "Th·ªùi gian": timestamp,
                "S·ªë c·ª•m": n_clusters if not pd.isna(n_clusters) else "N/A",
                "Silhouette Score": silhouette_value,
                "Run ID": run.info.run_id,
                "Experiment": experiment_name
            })
    
    df = pd.DataFrame(data, dtype='object')
    st.dataframe(df, hide_index=True, width=1000)
    return df, runs

# H√†m x√≥a log theo l·ª±a ch·ªçn
def clear_selected_logs(client, selected_runs):
    if not selected_runs:
        st.warning("Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt run ƒë·ªÉ x√≥a.")
        return
    
    with st.spinner("ƒêang x√≥a c√°c run ƒë√£ ch·ªçn..."):
        for run_id in selected_runs:
            client.delete_run(run_id)
        st.success(f"ƒê√£ x√≥a {len(selected_runs)} run th√†nh c√¥ng!")
    st.rerun()

# Giao di·ªán Streamlit (ch·ªâ hi·ªÉn th·ªã log hu·∫•n luy·ªán)
def view_clustering_logs():
    st.title("üìú Xem v√† Qu·∫£n l√Ω Log Hu·∫•n luy·ªán Clustering MNIST")

    # T·∫°o client MLflow
    client = MlflowClient()

    # Ch·ªâ hi·ªÉn th·ªã log t·ª´ MNIST_Train_Clustering (hu·∫•n luy·ªán)
    st.subheader("Log t·ª´ Experiment Hu·∫•n luy·ªán (MNIST_Train_Clustering)")
    with st.spinner("ƒêang t·∫£i log hu·∫•n luy·ªán..."):
        train_df, train_runs = display_logs(client, "MNIST_Train_Clustering")

    if train_df is not None and not train_df.empty:
        # L·∫•y danh s√°ch Run ID t·ª´ dataframe hu·∫•n luy·ªán
        train_run_ids = train_df["Run ID"].tolist()
        # Cho ph√©p ng∆∞·ªùi d√πng ch·ªçn run ƒë·ªÉ x√≥a
        selected_train_runs = st.multiselect("Ch·ªçn c√°c run hu·∫•n luy·ªán ƒë·ªÉ x√≥a", train_run_ids)
        if st.button("X√≥a c√°c run hu·∫•n luy·ªán ƒë√£ ch·ªçn", key="delete_train_runs"):
            clear_selected_logs(client, selected_train_runs)

    # Th√™m n√∫t l√†m m·ªõi cache v·ªõi key duy nh·∫•t
    if st.button("üîÑ L√†m m·ªõi d·ªØ li·ªáu", key=f"refresh_data_{datetime.datetime.now().microsecond}"):
        st.cache_data.clear()
        st.rerun()

# H√†m ch√≠nh
if __name__ == "__main__":
    view_clustering_logs()