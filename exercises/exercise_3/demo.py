import streamlit as st
import pandas as pd
import mlflow
from mlflow.tracking import MlflowClient
import os
import logging
import numpy as np
import datetime

# Thi·∫øt l·∫≠p logging ƒë·ªÉ debug n·∫øu c·∫ßn
logging.getLogger("mlflow").setLevel(logging.INFO)

# Thi·∫øt l·∫≠p MLflow v√† DagsHub
DAGSHUB_MLFLOW_URI = "https://dagshub.com/VietNam0410/ML_v3.mlflow"
mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
os.environ["MLFLOW_TRACKING_USERNAME"] = "VietNam0410"
os.environ["MLFLOW_TRACKING_PASSWORD"] = "c9db6bdcca1dfed76d2af2cdb15a9277e6732d6b"

# H√†m hi·ªÉn th·ªã v√† x√≥a log t·ª´ experiment, x·ª≠ l√Ω l·ªói ki·ªÉu d·ªØ li·ªáu
@st.cache_data
def display_logs(_client, experiment_name):
    experiment = _client.get_experiment_by_name(experiment_name)
    if not experiment:
        st.warning(f"Ch∆∞a c√≥ experiment '{experiment_name}'. S·∫Ω t·∫°o khi c√≥ log ƒë·∫ßu ti√™n.")
        return None, None
    
    runs = _client.search_runs(experiment_ids=[experiment.experiment_id])
    if not runs:
        st.warning(f"Kh√¥ng c√≥ log n√†o trong experiment '{experiment_name}'.")
        return None, None
    
    data = []
    for run in runs:
        run_name = run.data.tags.get("mlflow.runName", run.info.run_id)
        model_type = run.data.params.get("model_type", "N/A")
        log_time = run.data.params.get("log_time", datetime.datetime.fromtimestamp(run.info.start_time / 1000).strftime('%Y-%m-%d %H:%M:%S'))

        # L·∫•y c√°c tham s·ªë c·ª• th·ªÉ d·ª±a tr√™n model_type
        if model_type == "K-means":
            n_clusters = run.data.params.get("n_clusters", "N/A")
            eps = "N/A"
            min_samples = "N/A"
        elif model_type == "DBSCAN":
            n_clusters = run.data.metrics.get("n_clusters_found", "N/A")
            eps = run.data.params.get("eps", "N/A")
            min_samples = run.data.params.get("min_samples", "N/A")
        else:
            n_clusters = "N/A"
            eps = "N/A"
            min_samples = "N/A"

        # L·∫•y c√°c metrics
        silhouette_train = run.data.metrics.get("silhouette_train", np.nan)
        silhouette_valid = run.data.metrics.get("silhouette_valid", np.nan)
        training_duration = run.data.metrics.get("training_duration", np.nan)

        # Chuy·ªÉn ƒë·ªïi ki·ªÉu d·ªØ li·ªáu n·∫øu c·∫ßn
        silhouette_train = float(silhouette_train) if not pd.isna(silhouette_train) else np.nan
        silhouette_valid = float(silhouette_valid) if not pd.isna(silhouette_valid) else np.nan
        training_duration = float(training_duration) if not pd.isna(training_duration) else np.nan

        data.append({
            "T√™n Run": run_name,
            "Lo·∫°i M√¥ h√¨nh": model_type,
            "Th·ªùi gian Log": log_time,
            "S·ªë c·ª•m": n_clusters,
            "eps": eps,
            "min_samples": min_samples,
            "Silhouette Score (Train)": silhouette_train,
            "Silhouette Score (Valid)": silhouette_valid,
            "Th·ªùi gian hu·∫•n luy·ªán (gi√¢y)": training_duration,
            "Run ID": run.info.run_id,
            "Experiment": experiment_name
        })
    
    df = pd.DataFrame(data, dtype='object')
    st.dataframe(df, hide_index=True, width=1200)
    return df, runs

# H√†m x√≥a log theo l·ª±a ch·ªçn
def clear_selected_logs(client, selected_runs):
    if not selected_runs:
        st.warning("Vui l√≤ng ch·ªçn √≠t nh·∫•t m·ªôt run ƒë·ªÉ x√≥a.")
        return
    
    with st.spinner("ƒêang x√≥a c√°c run ƒë√£ ch·ªçn..."):
        for run_id in selected_runs:
            client.delete_run(run_id)
        st.success(f"ƒê√£ x√≥a {len(selected_runs)} run th√†nh c√¥ng!")
    st.rerun()

# Giao di·ªán Streamlit (ch·ªâ hi·ªÉn th·ªã log hu·∫•n luy·ªán)
def view_clustering_logs():
    st.title("üìú Xem v√† Qu·∫£n l√Ω Log Hu·∫•n luy·ªán Clustering MNIST")

    # T·∫°o client MLflow
    client = MlflowClient()

    # Ch·ªâ hi·ªÉn th·ªã log t·ª´ MNIST_Train_Clustering (hu·∫•n luy·ªán)
    st.subheader("Log t·ª´ Experiment Hu·∫•n luy·ªán (MNIST_Train_Clustering)")
    with st.spinner("ƒêang t·∫£i log hu·∫•n luy·ªán..."):
        train_df, train_runs = display_logs(client, "MNIST_Train_Clustering")

    if train_df is not None and not train_df.empty:
        # L·∫•y danh s√°ch Run ID t·ª´ dataframe hu·∫•n luy·ªán
        train_run_ids = train_df["Run ID"].tolist()
        # Cho ph√©p ng∆∞·ªùi d√πng ch·ªçn run ƒë·ªÉ x√≥a
        selected_train_runs = st.multiselect("Ch·ªçn c√°c run hu·∫•n luy·ªán ƒë·ªÉ x√≥a", train_run_ids)
        if st.button("X√≥a c√°c run hu·∫•n luy·ªán ƒë√£ ch·ªçn", key="delete_train_runs"):
            clear_selected_logs(client, selected_train_runs)
