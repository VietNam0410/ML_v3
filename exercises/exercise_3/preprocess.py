import streamlit as st
import numpy as np
import openml
from sklearn.model_selection import train_test_split
from tensorflow.keras.datasets import mnist
import mlflow
import os
import dagshub

# Thi·∫øt l·∫≠p th√¥ng tin DagsHub
DAGSHUB_USERNAME = "VietNam0410"
DAGSHUB_REPO = "vn0410"

try:
    dagshub.init(repo_owner=DAGSHUB_USERNAME, repo_name=DAGSHUB_REPO, mlflow=True)
    mlflow.set_tracking_uri(f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO}.mlflow")
    os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
    os.environ["MLFLOW_TRACKING_PASSWORD"] = os.getenv("MLFLOW_TRACKING_PASSWORD", "")
    st.success("ƒê√£ k·∫øt n·ªëi v·ªõi DagsHub th√†nh c√¥ng!")
except Exception as e:
    st.error(f"Kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi DagsHub: {str(e)}. S·ª≠ d·ª•ng MLflow c·ª•c b·ªô.")
    mlflow.set_tracking_uri(f"file://{os.path.abspath('mlruns')}")


def load_mnist_from_openml():
    try:
        dataset = openml.datasets.get_dataset(554)
        X, y, _, _ = dataset.get_data(target='class')
        X = X.values.reshape(-1, 28, 28, 1) / 255.0
        y = y.astype(np.int32)
        return X, y
    except Exception as e:
        st.error(f"Kh√¥ng th·ªÉ t·∫£i d·ªØ li·ªáu t·ª´ OpenML. S·ª≠ d·ª•ng d·ªØ li·ªáu t·ª´ TensorFlow: {str(e)}")
        (X_train, y_train), (X_test, y_test) = mnist.load_data()
        X = np.concatenate([X_train, X_test], axis=0) / 255.0
        y = np.concatenate([y_train, y_test], axis=0)
        return X.reshape(-1, 28, 28, 1), y

def preprocess_mnist_clustering():
    st.header("Ti·ªÅn x·ª≠ l√Ω D·ªØ li·ªáu MNIST cho Clustering üñåÔ∏è")

    if mlflow.active_run():
        mlflow.end_run()
        st.info("ƒê√£ ƒë√≥ng run MLflow ƒëang ho·∫°t ƒë·ªông tr∆∞·ªõc ƒë√≥.")

    experiment_name = st.text_input("Nh·∫≠p t√™n Experiment cho ti·ªÅn x·ª≠ l√Ω", value="MNIST_Clustering_Preprocessing")
    if experiment_name:
        mlflow.set_experiment(experiment_name)

    if 'X_full_clustering' not in st.session_state or 'y_full_clustering' not in st.session_state:
        st.session_state['X_full_clustering'], st.session_state['y_full_clustering'] = load_mnist_from_openml()
        st.success("D·ªØ li·ªáu MNIST ƒë√£ ƒë∆∞·ª£c t·∫£i v√† chu·∫©n h√≥a th√†nh c√¥ng! ‚úÖ")

    X_full = st.session_state['X_full_clustering']
    y_full = st.session_state['y_full_clustering']
    total_samples = len(X_full)

    st.subheader("Th√¥ng tin D·ªØ li·ªáu MNIST ƒê·∫ßy ƒë·ªß üîç")
    st.write(f"T·ªïng s·ªë l∆∞·ª£ng m·∫´u: {total_samples}")

    st.subheader("Chia t√°ch D·ªØ li·ªáu (T√πy ch·ªçn) üîÄ")
    max_samples = st.slider("Ch·ªçn s·ªë l∆∞·ª£ng m·∫´u t·ªëi ƒëa (0 ƒë·ªÉ d√πng to√†n b·ªô)", 0, total_samples, total_samples, step=100)
    
    if max_samples == 0:
        max_samples = total_samples
    elif max_samples > total_samples:
        st.error(f"S·ªë l∆∞·ª£ng m·∫´u ({max_samples}) v∆∞·ª£t qu√° t·ªïng s·ªë m·∫´u c√≥ s·∫µn ({total_samples}). ƒê·∫∑t l·∫°i v·ªÅ {total_samples}.")
        max_samples = total_samples

    test_size = st.slider("Ch·ªçn k√≠ch th∆∞·ªõc t·∫≠p ki·ªÉm tra (%)", min_value=10, max_value=50, value=20, step=5) / 100
    remaining_size = 1 - test_size
    train_size_relative = st.slider(
        "Ch·ªçn k√≠ch th∆∞·ªõc t·∫≠p hu·∫•n luy·ªán (% ph·∫ßn c√≤n l·∫°i sau test)",
        min_value=10, max_value=90, value=70, step=5
    ) / 100
    train_size = remaining_size * train_size_relative
    val_size = remaining_size * (1 - train_size_relative)

    st.write(f"T·ª∑ l·ªá d·ª± ki·∫øn: Hu·∫•n luy·ªán {train_size*100:.1f}%, Validation {val_size*100:.1f}%, Ki·ªÉm tra {test_size*100:.1f}%")

    if st.button("Chia d·ªØ li·ªáu"):
        if max_samples < total_samples:
            indices = np.random.choice(total_samples, max_samples, replace=False)
            X_subset = X_full[indices]
            y_subset = y_full[indices]
        else:
            X_subset = X_full
            y_subset = y_full

        X_remaining, X_test, y_remaining, y_test = train_test_split(
            X_subset, y_subset, test_size=test_size, random_state=42
        )
        X_train, X_valid, y_train, y_valid = train_test_split(
            X_remaining, y_remaining, test_size=val_size / remaining_size, random_state=42
        )

        st.success(f"ƒê√£ chia d·ªØ li·ªáu v·ªõi s·ªë l∆∞·ª£ng m·∫´u: {max_samples}. K√≠ch th∆∞·ªõc: Hu·∫•n luy·ªán {train_size*100:.1f}%, Validation {val_size*100:.1f}%, Ki·ªÉm tra {test_size*100:.1f}%! ‚úÖ")
        st.write(f"T·∫≠p hu·∫•n luy·ªán: {len(X_train)} m·∫´u")
        st.write(f"T·∫≠p validation: {len(X_valid)} m·∫´u")
        st.write(f"T·∫≠p ki·ªÉm tra: {len(X_test)} m·∫´u")

        with mlflow.start_run(run_name=f"MNIST_Clustering_Data_Split_{max_samples}_Samples") as run:
            mlflow.log_param("max_samples", max_samples)
            mlflow.log_param("train_size", train_size)
            mlflow.log_param("val_size", val_size)
            mlflow.log_param("test_size", test_size)
            mlflow.log_metric("train_samples", len(X_train))
            mlflow.log_metric("valid_samples", len(X_valid))
            mlflow.log_metric("test_samples", len(X_test))

            processed_file = "mnist_clustering_processed.npz"
            np.savez(processed_file, 
                     X_train=X_train, y_train=y_train,
                     X_valid=X_valid, y_valid=y_valid,
                     X_test=X_test, y_test=y_test)
            mlflow.log_artifact(processed_file, artifact_path="processed_data")
            os.remove(processed_file)

            run_id = run.info.run_id
            dagshub_link = f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO}/experiments/#/experiment/{experiment_name}/{run_id}"
            st.success("D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c chia v√† log v√†o MLflow ‚úÖ.")
            st.markdown(f"Xem chi ti·∫øt t·∫°i: [DagsHub Experiment]({dagshub_link})")

        st.session_state['mnist_clustering_data'] = {
            'X_train': X_train,
            'y_train': y_train,
            'X_valid': X_valid,
            'y_valid': y_valid,
            'X_test': X_test,
            'y_test': y_test
        }

if __name__ == "__main__":
    preprocess_mnist_clustering()