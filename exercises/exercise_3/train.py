import streamlit as st
import numpy as np
from sklearn.cluster import KMeans, DBSCAN
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import mlflow
import os
import dagshub
import datetime

# H√†m kh·ªüi t·∫°o MLflow
def mlflow_input():
    DAGSHUB_MLFLOW_URI = "https://dagshub.com/VietNam0410/vn0410.mlflow"
    mlflow.set_tracking_uri(DAGSHUB_MLFLOW_URI)
    st.session_state['mlflow_url'] = DAGSHUB_MLFLOW_URI
    os.environ["MLFLOW_TRACKING_USERNAME"] = "VietNam0410"
    os.environ["MLFLOW_TRACKING_PASSWORD"] = "22fd02345f8ff45482a20960058627630acaf190"  # Thay b·∫±ng token c√° nh√¢n c·ªßa b·∫°n
    DAGSHUB_REPO = "vn0410"
    return DAGSHUB_REPO
@st.cache_data
def train_clustering():
    st.header("Hu·∫•n luy·ªán M√¥ h√¨nh Clustering tr√™n MNIST üßÆ")

    # ƒê√≥ng b·∫•t k·ª≥ run n√†o ƒëang ho·∫°t ƒë·ªông ƒë·ªÉ tr√°nh xung ƒë·ªôt khi b·∫Øt ƒë·∫ßu
    if mlflow.active_run():
        mlflow.end_run()
        st.info("ƒê√£ ƒë√≥ng run MLflow ƒëang ho·∫°t ƒë·ªông tr∆∞·ªõc ƒë√≥.")

    # G·ªçi h√†m mlflow_input ƒë·ªÉ thi·∫øt l·∫≠p MLflow t·∫°i DAGSHUB_MLFLOW_URI
    DAGSHUB_REPO = mlflow_input()

    # Cho ng∆∞·ªùi d√πng ƒë·∫∑t t√™n Experiment
    experiment_name = st.text_input("Nh·∫≠p T√™n Experiment cho Hu·∫•n luy·ªán", value="MNIST_Clustering")
    with st.spinner("ƒêang thi·∫øt l·∫≠p Experiment tr√™n DagsHub MLflow..."):
        try:
            client = mlflow.tracking.MlflowClient()
            experiment = client.get_experiment_by_name(experiment_name)
            if experiment and experiment.lifecycle_stage == "deleted":
                st.warning(f"Experiment '{experiment_name}' ƒë√£ b·ªã x√≥a tr∆∞·ªõc ƒë√≥. Vui l√≤ng ch·ªçn t√™n kh√°c ho·∫∑c kh√¥i ph·ª•c experiment qua DagsHub UI.")
                new_experiment_name = st.text_input("Nh·∫≠p t√™n Experiment m·ªõi", value=f"{experiment_name}_Restored_{datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
                if new_experiment_name:
                    mlflow.set_experiment(new_experiment_name)
                    experiment_name = new_experiment_name
                else:
                    st.error("Vui l√≤ng nh·∫≠p t√™n experiment m·ªõi ƒë·ªÉ ti·∫øp t·ª•c.")
                    return
            else:
                mlflow.set_experiment(experiment_name)
        except Exception as e:
            st.error(f"L·ªói khi thi·∫øt l·∫≠p experiment: {str(e)}")
            return

    # Ki·ªÉm tra d·ªØ li·ªáu t·ª´ preprocess_mnist_clustering.py
    if 'mnist_clustering_data' not in st.session_state or st.session_state['mnist_clustering_data'] is None:
        st.error("D·ªØ li·ªáu MNIST cho clustering kh√¥ng t√¨m th·∫•y. Vui l√≤ng ho√†n t·∫•t ti·ªÅn x·ª≠ l√Ω trong 'Clustering Preprocess' tr∆∞·ªõc.")
        return

    mnist_data = st.session_state['mnist_clustering_data']
    if 'X_train' not in mnist_data:
        st.error("D·ªØ li·ªáu 'X_train' kh√¥ng t·ªìn t·∫°i trong session. Vui l√≤ng ho√†n t·∫•t ti·ªÅn x·ª≠ l√Ω tr∆∞·ªõc.")
        return

    st.subheader("D·ªØ li·ªáu MNIST ƒë√£ x·ª≠ l√Ω üìù")
    st.write(f"S·ªë l∆∞·ª£ng m·∫´u hu·∫•n luy·ªán: {len(mnist_data['X_train'])}")
    st.write(f"S·ªë l∆∞·ª£ng m·∫´u validation: {len(mnist_data.get('X_valid', []))}")
    st.write(f"S·ªë l∆∞·ª£ng m·∫´u ki·ªÉm tra: {len(mnist_data['X_test'])}")

    X_train = mnist_data['X_train'].reshape(-1, 28 * 28)
    X_valid = mnist_data.get('X_valid', mnist_data['X_test']).reshape(-1, 28 * 28)

    # Chu·∫©n h√≥a d·ªØ li·ªáu
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_valid_scaled = scaler.transform(X_valid)

    # Gi·∫£m chi·ªÅu d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã bi·ªÉu ƒë·ªì
    pca = PCA(n_components=2)
    X_train_pca = pca.fit_transform(X_train_scaled)
    X_valid_pca = pca.transform(X_valid_scaled)

    st.subheader("Gi·ªõi thi·ªáu thu·∫≠t to√°n Clustering")
    st.write("### K-means")
    st.write("K-means l√† m·ªôt thu·∫≠t to√°n ph√¢n c·ª•m kh√¥ng gi√°m s√°t, chia d·ªØ li·ªáu th√†nh K c·ª•m sao cho t·ªïng b√¨nh ph∆∞∆°ng kho·∫£ng c√°ch t·ª´ m·ªói ƒëi·ªÉm ƒë·∫øn t√¢m c·ª•m g·∫ßn nh·∫•t l√† nh·ªè nh·∫•t.")
    st.write("### DBSCAN")
    st.write("DBSCAN (Density-Based Spatial Clustering of Applications with Noise) ph√¢n c·ª•m d·ª±a tr√™n m·∫≠t ƒë·ªô ƒëi·ªÉm, kh√¥ng y√™u c·∫ßu x√°c ƒë·ªãnh tr∆∞·ªõc s·ªë c·ª•m, v√† c√≥ th·ªÉ ph√°t hi·ªán nhi·ªÖu.")

    st.subheader("Hu·∫•n luy·ªán M√¥ h√¨nh Clustering üéØ")
    model_choice = st.selectbox("Ch·ªçn thu·∫≠t to√°n clustering", ["K-means", "DBSCAN"])

    if model_choice == "K-means":
        n_clusters = st.slider("S·ªë l∆∞·ª£ng c·ª•m (K)", 2, 20, 10, step=1)
        max_iter = st.slider("S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa", 100, 1000, 300, step=100)
        model_params = {"n_clusters": n_clusters, "max_iter": max_iter, "random_state": 42}
    else:  # DBSCAN
        eps = st.slider("Kho·∫£ng c√°ch t·ªëi ƒëa (eps)", 0.1, 2.0, 0.5, step=0.1)
        min_samples = st.slider("S·ªë m·∫´u t·ªëi thi·ªÉu trong m·ªôt c·ª•m", 2, 20, 5, step=1)
        model_params = {"eps": eps, "min_samples": min_samples}

    # Cho ph√©p ng∆∞·ªùi d√πng ƒë·∫∑t t√™n run ID cho m√¥ h√¨nh
    run_name = st.text_input("Nh·∫≠p t√™n Run ID cho m√¥ h√¨nh clustering (ƒë·ªÉ tr·ªëng ƒë·ªÉ t·ª± ƒë·ªông t·∫°o)", value="", max_chars=20, key="clustering_run_name_input")
    if run_name.strip() == "":
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        run_name = f"MNIST_{model_choice}_Clustering_{timestamp.replace(' ', '_').replace(':', '-')}"  # ƒê·ªãnh d·∫°ng t√™n run h·ª£p l·ªá cho MLflow

    if st.button("Hu·∫•n luy·ªán v√† hi·ªÉn th·ªã k·∫øt qu·∫£"):
        # ƒê√≥ng b·∫•t k·ª≥ run n√†o ƒëang ho·∫°t ƒë·ªông tr∆∞·ªõc khi b·∫Øt ƒë·∫ßu
        if mlflow.active_run():
            mlflow.end_run()

        with st.spinner("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh clustering..."):
            if model_choice == "K-means":
                model = KMeans(**model_params)
            else:
                model = DBSCAN(**model_params)

            model.fit(X_train_scaled)
            labels = model.predict(X_valid_scaled) if model_choice == "K-means" else model.fit_predict(X_valid_scaled)
            n_clusters_found = len(np.unique(labels)) - (1 if -1 in labels else 0)  # ƒê·∫øm s·ªë c·ª•m, tr·ª´ nhi·ªÖu n·∫øu c√≥

            st.write(f"Thu·∫≠t to√°n: {model_choice}")
            st.write(f"Tham s·ªë: {model_params}")
            st.write(f"S·ªë c·ª•m t√¨m th·∫•y: {n_clusters_found}")

            # V·∫Ω bi·ªÉu ƒë·ªì
            fig, ax = plt.subplots()
            scatter = ax.scatter(X_valid_pca[:, 0], X_valid_pca[:, 1], c=labels, cmap="viridis", s=10)
            plt.colorbar(scatter)
            plt.title(f"{model_choice} Clustering tr√™n MNIST (PCA 2D)")
            plt.xlabel("PCA Component 1")
            plt.ylabel("PCA Component 2")
            st.pyplot(fig)

            # L∆∞u bi·ªÉu ƒë·ªì c·ª•c b·ªô tr∆∞·ªõc khi log v√†o MLflow
            plot_file = "clustering_plot.png"
            fig.savefig(plot_file)

            # Logging v√†o MLflow t·∫°i DAGSHUB_MLFLOW_URI
            timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            with mlflow.start_run(run_name=run_name) as run:
                mlflow.log_param("timestamp", timestamp)
                mlflow.log_param("run_id", run.info.run_id)
                mlflow.log_params(model_params)
                mlflow.log_param("model_type", model_choice)
                mlflow.log_metric("n_clusters_found", n_clusters_found)
                mlflow.sklearn.log_model(model, "model", input_example=X_train_scaled[:1])
                mlflow.sklearn.log_model(scaler, "scaler", input_example=X_train[:1])
                mlflow.sklearn.log_model(pca, "pca", input_example=X_train_scaled[:1])

                # Log bi·ªÉu ƒë·ªì l√†m artifact
                mlflow.log_artifact(plot_file, artifact_path="plots")
                os.remove(plot_file)  # X√≥a file c·ª•c b·ªô sau khi log

                run_id = run.info.run_id
                mlflow_uri = st.session_state['mlflow_url']
                st.success(f"Hu·∫•n luy·ªán {model_choice} ho√†n t·∫•t v√† log v√†o DagsHub MLflow th√†nh c√¥ng! ‚úÖ (T√™n Run: {run_name}, Run ID: {run_id}, Th·ªùi gian: {timestamp})")
                st.markdown(f"Xem chi ti·∫øt t·∫°i: [DagsHub MLflow Tracking]({mlflow_uri})")

            # L∆∞u m√¥ h√¨nh, scaler, PCA, v√† nh√£n v√†o session_state ƒë·ªÉ s·ª≠ d·ª•ng sau
            st.session_state['clustering_model'] = model
            st.session_state['clustering_scaler'] = scaler
            st.session_state['clustering_pca'] = pca
            st.session_state['clustering_labels'] = labels

if __name__ == "__main__":
    train_clustering()