import streamlit as st
import numpy as np
from sklearn.cluster import KMeans, DBSCAN
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
import mlflow
import os
import dagshub

# Thi·∫øt l·∫≠p th√¥ng tin DagsHub
DAGSHUB_USERNAME = "VietNam0410"
DAGSHUB_REPO = "vn0410"

try:
    dagshub.init(repo_owner=DAGSHUB_USERNAME, repo_name=DAGSHUB_REPO, mlflow=True)
    mlflow.set_tracking_uri(f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO}.mlflow")
    os.environ["MLFLOW_TRACKING_USERNAME"] = DAGSHUB_USERNAME
    os.environ["MLFLOW_TRACKING_PASSWORD"] = os.getenv("MLFLOW_TRACKING_PASSWORD", "")
    st.success("ƒê√£ k·∫øt n·ªëi v·ªõi DagsHub th√†nh c√¥ng!")
except Exception as e:
    st.error(f"Kh√¥ng th·ªÉ k·∫øt n·ªëi v·ªõi DagsHub: {str(e)}. S·ª≠ d·ª•ng MLflow c·ª•c b·ªô.")
    mlflow.set_tracking_uri(f"file://{os.path.abspath('mlruns')}")

def train_clustering():
    st.header("Hu·∫•n luy·ªán M√¥ h√¨nh Clustering tr√™n MNIST üßÆ")

    if mlflow.active_run():
        mlflow.end_run()
        st.info("ƒê√£ ƒë√≥ng run MLflow ƒëang ho·∫°t ƒë·ªông tr∆∞·ªõc ƒë√≥.")

    experiment_name = st.text_input("Nh·∫≠p T√™n Experiment cho Hu·∫•n luy·ªán", value="MNIST_Clustering")
    if experiment_name:
        mlflow.set_experiment(experiment_name)

    if 'mnist_clustering_data' not in st.session_state or st.session_state['mnist_clustering_data'] is None:
        st.error("D·ªØ li·ªáu MNIST cho clustering kh√¥ng t√¨m th·∫•y. Vui l√≤ng ho√†n t·∫•t ti·ªÅn x·ª≠ l√Ω trong 'Clustering Preprocess' tr∆∞·ªõc.")
        return

    mnist_data = st.session_state['mnist_clustering_data']
    if 'X_train' not in mnist_data:
        st.error("D·ªØ li·ªáu 'X_train' kh√¥ng t·ªìn t·∫°i trong session. Vui l√≤ng ho√†n t·∫•t ti·ªÅn x·ª≠ l√Ω tr∆∞·ªõc.")
        return

    st.subheader("D·ªØ li·ªáu MNIST ƒë√£ x·ª≠ l√Ω üìù")
    st.write(f"S·ªë l∆∞·ª£ng m·∫´u hu·∫•n luy·ªán: {len(mnist_data['X_train'])}")
    st.write(f"S·ªë l∆∞·ª£ng m·∫´u validation: {len(mnist_data.get('X_valid', []))}")
    st.write(f"S·ªë l∆∞·ª£ng m·∫´u ki·ªÉm tra: {len(mnist_data['X_test'])}")

    X_train = mnist_data['X_train'].reshape(-1, 28 * 28)
    X_valid = mnist_data.get('X_valid', mnist_data['X_test']).reshape(-1, 28 * 28)

    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_valid_scaled = scaler.transform(X_valid)

    # Gi·∫£m chi·ªÅu d·ªØ li·ªáu ƒë·ªÉ hi·ªÉn th·ªã bi·ªÉu ƒë·ªì
    pca = PCA(n_components=2)
    X_train_pca = pca.fit_transform(X_train_scaled)
    X_valid_pca = pca.transform(X_valid_scaled)

    st.subheader("Gi·ªõi thi·ªáu thu·∫≠t to√°n Clustering")
    st.write("### K-means")
    st.write("K-means l√† m·ªôt thu·∫≠t to√°n ph√¢n c·ª•m kh√¥ng gi√°m s√°t, chia d·ªØ li·ªáu th√†nh K c·ª•m sao cho t·ªïng b√¨nh ph∆∞∆°ng kho·∫£ng c√°ch t·ª´ m·ªói ƒëi·ªÉm ƒë·∫øn t√¢m c·ª•m g·∫ßn nh·∫•t l√† nh·ªè nh·∫•t.")
    st.write("### DBSCAN")
    st.write("DBSCAN (Density-Based Spatial Clustering of Applications with Noise) ph√¢n c·ª•m d·ª±a tr√™n m·∫≠t ƒë·ªô ƒëi·ªÉm, kh√¥ng y√™u c·∫ßu x√°c ƒë·ªãnh tr∆∞·ªõc s·ªë c·ª•m, v√† c√≥ th·ªÉ ph√°t hi·ªán nhi·ªÖu.")

    st.subheader("Hu·∫•n luy·ªán M√¥ h√¨nh Clustering üéØ")
    model_choice = st.selectbox("Ch·ªçn thu·∫≠t to√°n clustering", ["K-means", "DBSCAN"])

    if model_choice == "K-means":
        n_clusters = st.slider("S·ªë l∆∞·ª£ng c·ª•m (K)", 2, 20, 10, step=1)
        max_iter = st.slider("S·ªë l·∫ßn l·∫∑p t·ªëi ƒëa", 100, 1000, 300, step=100)
        model_params = {"n_clusters": n_clusters, "max_iter": max_iter, "random_state": 42}
    else:  # DBSCAN
        eps = st.slider("Kho·∫£ng c√°ch t·ªëi ƒëa (eps)", 0.1, 2.0, 0.5, step=0.1)
        min_samples = st.slider("S·ªë m·∫´u t·ªëi thi·ªÉu trong m·ªôt c·ª•m", 2, 20, 5, step=1)
        model_params = {"eps": eps, "min_samples": min_samples}

    if st.button("Hu·∫•n luy·ªán v√† hi·ªÉn th·ªã k·∫øt qu·∫£"):
        with mlflow.start_run(run_name=f"{model_choice}_MNIST_Clustering") as run:
            if model_choice == "K-means":
                model = KMeans(**model_params)
            else:
                model = DBSCAN(**model_params)

            model.fit(X_train_scaled)
            labels = model.predict(X_valid_scaled) if model_choice == "K-means" else model.fit_predict(X_valid_scaled)
            n_clusters_found = len(np.unique(labels)) - (1 if -1 in labels else 0)  # ƒê·∫øm s·ªë c·ª•m, tr·ª´ nhi·ªÖu n·∫øu c√≥

            st.write(f"Thu·∫≠t to√°n: {model_choice}")
            st.write(f"Tham s·ªë: {model_params}")
            st.write(f"S·ªë c·ª•m t√¨m th·∫•y: {n_clusters_found}")

            # V·∫Ω bi·ªÉu ƒë·ªì
            fig, ax = plt.subplots()
            scatter = ax.scatter(X_valid_pca[:, 0], X_valid_pca[:, 1], c=labels, cmap="viridis", s=10)
            plt.colorbar(scatter)
            plt.title(f"{model_choice} Clustering tr√™n MNIST (PCA 2D)")
            plt.xlabel("PCA Component 1")
            plt.ylabel("PCA Component 2")
            st.pyplot(fig)

            # Log v√†o MLflow
            mlflow.log_params(model_params)
            mlflow.log_param("model_type", model_choice)
            mlflow.log_metric("n_clusters_found", n_clusters_found)
            mlflow.sklearn.log_model(model, "model", input_example=X_train_scaled[:1])
            mlflow.sklearn.log_model(scaler, "scaler", input_example=X_train[:1])
            mlflow.sklearn.log_model(pca, "pca", input_example=X_train_scaled[:1])

            # L∆∞u bi·ªÉu ƒë·ªì
            plt.savefig("clustering_plot.png")
            mlflow.log_artifact("clustering_plot.png", artifact_path="plots")
            os.remove("clustering_plot.png")

            run_id = run.info.run_id
            dagshub_link = f"https://dagshub.com/{DAGSHUB_USERNAME}/{DAGSHUB_REPO}/experiments/#/experiment/{experiment_name}/{run_id}"
            st.success(f"Hu·∫•n luy·ªán {model_choice} ho√†n t·∫•t v√† log v√†o MLflow ‚úÖ (Run ID: {run_id})")
            st.markdown(f"Xem chi ti·∫øt t·∫°i: [DagsHub Experiment]({dagshub_link})")

            st.session_state['clustering_model'] = model
            st.session_state['clustering_scaler'] = scaler
            st.session_state['clustering_pca'] = pca
            st.session_state['clustering_labels'] = labels

if __name__ == "__main__":
    train_clustering()